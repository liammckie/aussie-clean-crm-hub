Technical Specification – Commercial Cleaning Quoting Module
Overview and Scope
The Commercial Cleaning Quoting Module is an internal web-based tool for generating detailed cleaning service quotes as part of the company’s ERP system. It enables users (estimators) to build multi-site cleaning scopes of work with accurate time and cost estimates, using industry-standard productivity rates. Key features of the module include:
Task Database Management: Maintain a library of cleaning tasks with standard productivity rates (sourced from ISSA guidelines, adjusted ~20% for local Australian conditions【13†L493-L498】). This task database serves as the basis for all time calculations in quotes.
Multi-Site Quote Builder: Create quotes that cover one or multiple sites. For each site, users can specify the tasks to be performed, the frequency of each task, the area or quantity, and the shift type (weekday, weekend, or public holiday) for performing that task.
Productivity-Based Calculations: Automatically calculate the labor hours required for each task based on the task’s productivity rate and the specified area/units and frequency【13†L480-L488】【13†L516-L520】. Roll these up into total hours per site and for the entire quote.
Costing and Pricing Engine: Support two labor cost modes – (1) Award-based (using the Australian Cleaning Services Award MA000022 rules for wages, including an​

gs, weekend/public holiday penalty rates, and typical allowances) and (2) Contractor rate (a flat hourly labor cost). The engine applies overhead costs, equipment depreciation costs, and profit margin to produce final pricing.
Financial Metrics: Present key financial outcomes for the quote, including Monthly Recurring Revenue, Gross Profit (before overhead & equipment costs), Net Profit (after all costs), and Profit Margin. These are derived from the detailed cost buildup. Additionally, provide a breakdown of revenue and cost on weekly, monthly, and annual bases for transparency.
Scenario Analysis (“What-If”): Allow users to adjust parameters on the fly – for example, tweak the target profit margin or hourly rates, change task frequencies or shift assignments – and immediately see updated quotes. This helps in exploring scenarios such as “What if we require a 5% higher margin?” or “What if weekend tasks are moved to weekdays?”.
Quote Records and Export: Every generated quote is saved in the system, with the responsible user’s name and the client name recorded (both are mandatory inputs). Users can review past quotes, export summary data (as CSV or JSON), or print a formatted quote summary for sharing with stakeholders.
Out of Scope: This quoting module focuses solely on estimating the labor and service costs for cleaning contracts. It is not intended to handle downstream contract approval, billing/invoicing, or workforce scheduling/management of staff. Those functions are either handled by other ERP modules or future enhancements. The quote outputs are for internal use to inform pricing proposals, not for automated contract generation. The module will be built with the existing technology stack: Next.js (React) for the front-end UI, Tailwind CSS for styling, and Supabase (PostgreSQL) for data storage (taking advantage of Supabase’s hosted database and authentication). The following sections detail the database design, API endpoints, front-end architecture, calculation engine, and integration considerations.
Database Schema
The application will introduce several new tables in the Supabase (Postgres) database. Below is the schema design with tables and key fields. Relations use primary keys (IDs) to link records, and foreign keys ensure referential integrity. All timestamps (created_at, updated_at) are omitted for brevity but will be included for audit trail on each table.
Users
The system will use the ERP’s existing user accounts (likely managed via Supabase Auth). We assume a users table (or Supabase’s built-in auth.users) exists. Each quote will reference the user who created it. Minimal user info needed for this module is the user’s unique ID and name.
user_id (PK): Unique identifier for the user (UUID as provided by Supabase Auth).
name: User’s full name (for display on quotes).
email: (If needed, for notification or record; might already exist in auth).
Integration note: We will rely on Supabase Auth for user management, so the quoting module will use the authenticated user’s ID from the session for any create/read operations. No separate password handling is needed here.
Tasks
The tasks table stores the library of cleaning tasks and their standard productivity rates. This is seeded initially with data from the ISSA Cleaning Times reference, with a 20% time adjustment to reflect Australian conditions (since ISSA figures are benchmarks that often need local adjustment【13†L493-L498】). Users with proper permission can manage (add/edit) these tasks as needed over time.
task_id (PK): Unique ID for the task (UUID or serial).
name: Descriptive name of the task (e.g. "Vacuum Carpets", "Mop Hard Floors").
category: Category or group the task belongs to (for organizational purposes, e.g. "Floor Care", "Restrooms"). Categories could be free text or a reference to a categories table. (For now, a text field is sufficient; it helps group tasks in the UI.)
unit_type: The unit of measure for the task productivity, indicating what the quantity refers to. Examples: "sqm" (square meters), "sqft", "each" (per item), "fixture", etc. This helps the UI prompt the correct input (area vs count).
productivity_rate: The standard productivity rate of the task. This can be stored as output per hour by one worker. For example, if a worker can clean 100 square meters of carpet in 1 hour, the productivity_rate = 100 (sqm/hour). If a task is measured per item (e.g. 10 fixtures/hour), store that number. All rates in the DB will already include the 20% adjustment for Australian conditions. (Alternatively, store the base ISSA rate and a separate adjustment factor, but applying the factor upfront simplifies usage.)
baseline_minutes_per_unit (optional): Instead of or in addition to productivity_rate, we might store how many minutes one unit takes. This can be derived (since minutes per unit = 60 / productivity_rate for area tasks). For example, if productivity_rate is 100 sqm/hour, minutes_per_unit for 1 sqm = 0.6 minutes. Storing one or the other is sufficient. We will use productivity_rate for calculations.
description (optional): Longer text describing the task or its scope (if needed for clarity).
Example: A task "Mop Tile Floor" might have unit_type "sqm" and productivity_rate = 300, meaning one cleaner can mop 300 m² per hour on average. A task "Clean Toilet Fixture" might have unit_type "each" and productivity_rate = 20 (fixtures/hour). These values come from ISSA’s guidelines and can be edited if on-site studies show different performance.
Shift Types
The shifts table defines the categories of shift timing that affect labor cost rates under award-based costing. We will define three shift types as per requirements: weekday, weekend, and public holiday. Each shift type entry carries the multiplier or loading to apply on top of base hourly wages (per the Cleaning Award MA000022). This allows the cost calculation to adjust wages for work done on weekends or holidays.
shift_id (PK): Unique ID for the shift type.
name: Name of shift category – e.g. "Weekday", "Weekend", "Public Holiday".
award_multiplier: The pay rate multiplier relative to the base wage, for award-based costing. For example, Weekday might be 1.0 (base rate), Weekend might be 1.5 (150% pay), Public Holiday 2.5 (250% pay). These are approximate; exact Award rules can be more complex (Sat vs Sun differ, etc.), but we will use a representative multiplier for simplicity. (We assume “Weekend” covers both Saturday and Sunday with a single multiplier. In future this could be split if needed.)
description: (Optional) Description of the shift or any notes (e.g. “Use 1.5× for any weekend day work as a simplification of Sat/Sun penalties”).
Rationale: The Award MA000022 specifies penalty rates such as 150% for Saturdays and 200% for Sundays for full-time/part-time employees (casuals incur an additional loading)【17†L97-L105】. We will use a single weekend multiplier (likely ~1.5 or 1.75) to cover typical weekend cost, recognizing Sunday is higher. For public holidays, double-time-and-a-half (2.5×) is common【17†L103-L110】. These multipliers will be used to inflate the base hourly wage for any hours classified in that shift.
Costing Configs
The costing_configs table stores parameters for the cost calculations, particularly labor rates and overhead settings. It allows the system to support both Award-based and Contractor costing modes, and can be extended or updated as rates change. We anticipate at least two records in this table (one for each mode), or possibly multiple versions over time (if wages are updated annually, new records could be added with effective dates). Fields for a costing_config may include:
config_id (PK): Unique ID for the costing configuration.
name: Name/label of the configuration (e.g. "Award 2025 Rates", "Contractor Rate Std").
mode: "award" or "contractor" – identifies which labor costing approach this config represents.
base_hourly_rate: The base hourly wage rate. For award mode, this would correspond to the normal hourly pay for a cleaner (e.g. the Level 1 Cleaning Service Employee rate). For contractor mode, this could be left null or used similarly (though contractor mode will primarily use the flat rate field below).
casual_loading_pct: (Award mode) The additional percentage for casual employees. The Award specifies 25% loading for casuals【15†L7-L15】. If the company’s quoting assumes use of casual labor, this can be 25. If assuming full-time, this could be 0. (We can incorporate this into the base_rate if we assume one or the other to simplify real-time calc.)
award_allowances_per_hour: (Award mode, optional) Any average allowance cost per hour of work. This could factor in things like uniform, laundry, travel time allowances, etc., averaged out. For simplicity this might be a small fixed addition (e.g. $1/hour) to cover typical allowances. (Alternatively, we handle a fixed cost per shift separately, but for quoting we’ll likely roll minor allowances into an hourly cost adder.)
contractor_hourly_rate: (Contractor mode) The flat hourly cost rate if using subcontractors. This is what the contractor charges us per hour of work (e.g. $45/hour flat, regardless of weekend or not, since the contractor handles their own penalties).
overhead_pct: Percentage of direct labor cost to add as overhead. This accounts for indirect costs (management, insurance, admin) associated with providing the service. For example, 15% overhead means we will add 15% of labor+contractor costs as an overhead cost.
equipment_cost_per_hour: A rate (in $) to represent equipment depreciation and supplies per hour of cleaning. For example, $2/hour might be added to cover the wear-and-tear and consumables (chemicals, tools) used. This could also be represented as a percentage of labor, but a per-hour flat rate is straightforward.
default_profit_margin_pct: (Optional) A default profit margin target. This might be used as an initial suggestion in quotes (e.g. aim for 30% margin). Profit margin in quoting is handled by setting the charge rate to achieve the desired margin.
Only certain fields are used depending on the mode. For instance, in award mode, we use base_rate, casual_loading, etc., while in contractor mode we primarily use contractor_hourly_rate. The overhead and equipment fields are applicable to both modes. The system can come pre-configured with known Award rates (e.g. base rate $25/hour for Level 1, casual loading 25%, etc.) and a default contractor rate if applicable. Admin users should be able to update this table as wages or cost assumptions change over time (ensuring quotes stay up-to-date with current costs).
Quotes
The quotes table is the parent record for each saved quote. It contains high-level information about the quote and relationships to associated sites and scope items. Each quote represents a proposal for recurring cleaning services (usually priced per month).
quote_id (PK): Unique identifier for the quote.
client_name: Name of the client or organization the quote is for. (This is a required field input by the user when creating the quote.) It may just be a text field here, or potentially a foreign key to a clients table if the ERP has one. In this module we will treat it as text input.
created_by: Reference to user_id of the Users table – the user who created the quote. This is recorded automatically to track accountability.
created_at: Timestamp when the quote was created.
labor_mode: The labor costing mode used for this quote ("award" or "contractor"). This determines which costing method was applied in calculations.
config_id: (Optional) Reference to the costing_configs used. If we maintain historical configs, this links the quote to the specific costing assumptions at that time. Alternatively, we might store some of the cost parameters directly on the quote to freeze them (see below).
margin_pct: The profit margin percentage applied on this quote (if applicable). For instance, if the user targeted a 20% profit margin, this would be 20.0. This helps record the pricing strategy.
monthly_price: The total monthly recurring price quoted to the client (Revenu​
PAYCAT.COM.AU
n be stored for quick reference, even though it can be derived from details.
gross_profit: (Optional, can be derived) Gross profit dollar amount = monthly_price - labor_cost (before overhead/equipment).
net_profit: (Optional) Net profit dollar amount = monthly_price - (labor_cost + overhead_cost + equipment_cost).
profit_margin_pct: (Optional, can be derived) Profit margin = net_profit / monthly_price * 100%.
status: (Optional) Status of the quote (e.g. “Draft”, “Finalized”, “Accepted”, etc.). Initially, all quotes might just be considered final once saved. We might include this for future workflow.
Note: Storing the calculated financial results (price, profits) redundantly in the quotes table can be helpful to preserve a snapshot of what was quoted. This is especially important if cost inputs (like wage rates) change later – we don’t want historical quotes to be recalculated with new rates. By linking to a specific config_id or storing the numbers, we ensure the quote remains as originally given. We will implement either approach: link to a dated config or save the computed cost rates. For example, we might store effective_hourly_cost_rate on the quote if using contractor mode (so we know which rate was used), or effective_base_rate and multipliers if award mode. This level of detail ensures fidelity of historical data (and could aid future analysis).
Sites (Quote Sites)
The quote_sites table represents individual site locations included in a multi-site quote. Each quote can have one or more sites. If a quote only has one site, there will be one entry here. We separate sites to allow per-site breakdown of tasks and possibly to show per-site subtotals in the future.
site_id (PK): Unique identifier for the site entry (could be auto-generated).
quote_id (FK -> quotes.quote_id): The quote to which this site belongs.
site_name: Name or identifier for the site. This could be a location name (e.g. “Head Office”, “Warehouse 2”, “Melbourne Campus Building A”). The user will input this when adding a site to the quote.
site_address: (Optional) Physical address of the site, if relevant for reference. Not strictly needed for quoting calculations, but useful for the record or print-out.
notes: (Optional) Any additional notes about the site (e.g. “24/7 operation, no cleaning on Sundays” – if relevant to scope).
In many cases, the site_name is sufficient to distinguish sites in the quote. The site table mainly groups the task scope items (described next) and could be used later to integrate with a client/site database if needed.
Quote Scope Items (Tasks per Site)
The quote_scope_items table (or simply quote_tasks) contains the detailed line items of the scope of work for each site in the quote. Each record represents a specific task being performed at a specific site with a given frequency and workload. This is essentially the heart of the quote where all the input variables are captured.
scope_item_id (PK): Unique ID for this scope line item.
quote_id (FK -> quotes.quote_id): Reference to the parent quote.
site_id (FK -> quote_sites.site_id): Reference to the site within that quote where this task will be performed.
task_id (FK -> tasks.task_id): Reference to the task being performed (to pull in the productivity rate and unit).
frequency: The frequency of service for this task. This can be expressed in terms of occurrences per week (or per month). We will allow common inputs like “daily”, “weekly”, “monthly” in the UI, but store a numeric value. For storage, one approach is:
frequency_per_week (decimal): e.g. 5 for daily weekdays (5x per week), 7 for daily including weekends, 1 for weekly, 0.5 for biweekly (every 2 weeks, which is 0.5/week), 0.23 for monthly (approx 1 per 4.33 weeks).
Alternatively, store two fields: frequency_count and frequency_unit (where unit can be "per week", "per month", etc.). For simplicity, we use a normalized per-week value to facilitate calculations. We will interpret this appropriately (in calculations we convert weekly freq to monthly by multiplying by ~4.33).
quantity: The quantity of work for this task at this site. The meaning of this number depends on the task’s unit:
If the task is area-based (unit_type = sqm or sqft), this field is the total area to be cleaned each time (e.g. 500 m² of carpet to vacuum at the site).
If the task is item-based (unit_type = each, fixture, etc.), this is the count of items (e.g. 10 trash bins to empty, 15 fixtures to clean).
The UI label will adapt (showing “Area (sqm)” or “Units” accordingly) to guide input.
shift_id (FK -> shifts.shift_id): The shift category in which this task will typically be performed at this site. For example, a task might be scheduled during regular weekdays (shift_id for Weekday), or perhaps on weekends (shift_id for Weekend) if that task is only done during off-hours or if the facility is cleaned on weekends. This selection drives the labor cost multiplier in award mode.
time_per_service: (Optional, calculated) The estimated labor time required per service occurrence of this task (in hours). This is derived from quantity and task productivity. For example, if quantity is 500 m² and task productivity_rate is 250 m²/hour, then time_per_service = 2.0 hours. This is stored either for convenience or calculated on the fly each time.
monthly_hours: (Optional, calculated) The total labor hours per month for this task. This would be time_per_service * number_of_services_per_month. If frequency_per_week i​
ISSA.COM
ly services ≈ freq_per_week * 4.33. Using the above example, if vacuuming (500 m², 2 hours each service) is done 5 times a week, monthly_hours ≈ 2 * (5 * 4.33) ≈ 43.3 hours/month.
cost_rate_override: (Optional) A custom labor cost rate to use for this task line (per hour), overriding the default from the costing config. Normally, all tasks on a quote share the same underlying labor cost assumptions. But in special cases, a user might want to adjust a particular task’s cost. For example, if a highly specialized task is subcontracted separately at a different rate. This field can be null to indicate use standard calculation, or if set, that rate will be used for cost calculations for this line.
charge_rate_override: (Optional) A custom charge rate (price per hour) to the client for this specific task, overriding the general pricing. Usually not needed (generally we price all hours uniformly), but this could allow special cases (e.g. charging a premium for high-difficulty tasks or a discount for simple tasks). If null, the module will assume a standard charge rate or a global margin across all tasks.
When a quote is finalized and saved, the system will iterate through these scope items to calculate totals. We may choose to store the computed totals in the quote (as above). The detail records themselves (quote_scope_items) contain all info needed to recompute if necessary. Relationships: quotes -> quote_sites is one-to-many. quote_sites -> quote_scope_items is one-to-many. We ensure cascading deletes: if a quote is deleted, all its sites and scope items should delete (or be archived) as well. Deleting a task from the tasks library should probably be prevented if it’s used in any quote_scope_items (to preserve historical record integrity). Instead, tasks can be marked inactive if needed. Database Example: After a user creates a quote for “Client A” with 2 sites, each with several tasks, the tables might have entries like:
quotes: 1 record (Client A, created_by User X, labor_mode = "award", margin_pct = 30, monthly_price = $10,000, etc.)
quote_sites: 2 records (e.g. Site 1 = "Headquarters", Site 2 = "Warehouse")
quote_scope_items: multiple records, e.g.
(quote_id -> Quote A, site_id -> HQ, task = Vacuum Carpets, frequency_per_week 5, qty 1000 sqm, shift = Weekday),
(quote_id -> Quote A, site_id -> HQ, task = Mop Floors, frequency 5, qty 800 sqm, shift = Weekday),
(quote_id -> Quote A, site_id -> HQ, task = Sanitize Restrooms, frequency 3, qty 10 fixtures, shift = Weekday),
(quote_id -> Quote A, site_id -> Warehouse, task = Vacuum Carpets, freq 3, qty 500 sqm, shift = Weekend),
etc.
This structure is flexible and normalized. We can easily query, for example, all tasks for a given quote (join quote_scope_items with tasks), or the total hours per site, etc.
API Endpoints and Structure
We will implement a set of RESTful API endpoints (within Next.js API routes) to allow the front-end to interact with this data and perform operations. All endpoints will require an authenticated user (the system will check the Supabase auth session or JWT). Where appropriate, authorization checks will ensure users only access their own data (if quotes are private per user) or are limited by role. In an internal company context, it might be acceptable that all authorized users see all quotes; this can be configured as needed. Below are the primary endpoints:
Task Management APIs
GET /api/tasks – List all tasks. Returns a JSON array of task objects from the tasks table (id, name, category, unit_type, productivity_rate, etc). Used to populate task dropdowns or for viewing the task library. Supports query filters or pagination if the task list is large (though typically manageable).
POST /api/tasks – Create a new task. Accepts JSON body with task details (name, category, unit_type, base productivity, etc). This will insert a new record into the tasks table. Only authorized users (e.g. admin or estimator role) can add tasks. This could be used to add custom tasks or adjust the library beyond the ISSA-imported ones.
PUT /api/tasks/{id} – Update an existing task. Allows editing fields of a task (e.g. adjust the productivity_rate or name). This might be restricted if the task is in use by quotes (to avoid retroactively affecting past quotes’ calculations). A safe approach is to allow edits for future use but not recalc old quotes, as those have stored values. We will document that historical quotes aren’t automatically updated by changing task rates.
DELETE /api/tasks/{id} – Remove a task. This may be either disallowed or implemented as a “soft delete” (marking the task inactive) if the task is referenced in any quote. We likely won’t truly delete tasks that are in use. For now, we can omit implementing delete, or allow it only for tasks with no associated quote items. (An alternative is to have an active flag in tasks table and simply filter out inactive ones in GET.)
(Note: Instead of building a custom import endpoint for ISSA data, we will import the provided Excel offline and populate the tasks table as an initial migration/seed. If needed, an admin-only endpoint or script can be created to import tasks in bulk from a CSV/Excel. This is a one-time setup task and not part of regular user operations.)
Quoting (Scope) APIs
POST /api/quotes – Create a new quote. This is called when the user finalizes a quote in the UI. The payload will include the quote details: client name, an array of sites, and the scope items for each site, as well as the chosen costing mode and margin. For example, the JSON might look like:
json
Copy
Edit
{
  "client_name": "Client A",
  "labor_mode": "award",
  "margin_pct": 30,
  "sites": [
    {
      "site_name": "Head Office",
      "tasks": [
        { "task_id": "...", "frequency_per_week": 5, "quantity": 1000, "shift_id": "weekday" },
        { "task_id": "...", "frequency_per_week": 5, "quantity": 800, "shift_id": "weekday" },
        { "task_id": "...", "frequency_per_week": 3, "quantity": 10,  "shift_id": "weekday" }
      ]
    },
    {
      "site_name": "Warehouse",
      "tasks": [
        { "task_id": "...", "frequency_per_week": 3, "quantity": 500, "shift_id": "weekend" }
      ]
    }
  ]
}
The server handler will:
Validate the data (all required fields present, frequencies and quantities are positive, etc.).
Perform the quote calculations (using the calculation engine described later) to compute the totals (monthly hours, costs, price, profit, etc).
Insert a new quote record (quotes table) with basic info (client_name, user, mode, margin, and computed totals).
Insert the site records (quote_sites table) for each site.
Insert all scope items (quote_scope_items table) linked to those sites.
If all inserts succeed, return a success response with the new quote_id and perhaps the computed summary. This operation should ideally be atomic. We will use a database transaction (via Supabase or a single stored procedure call) to ensure that all related inserts succeed or all fail (to avoid partial quotes).
GET /api/quotes – List quotes. Returns a list of quotes accessible to the user. Likely returns a summary (quote_id, client_name, created_by, date, total price, profit margin). If the system is multi-user, a regular user might see only their own quotes, while an admin could see all. We can implement a filter by user = current user for non-admin roles. Query parameters could allow filtering by date range or client.
GET /api/quotes/{id} – Get quote details. Returns the full details of a specific quote, including its sites and tasks. The response JSON will be structured with nested data, for example:
json
Copy
Edit
{
  "quote_id": "...",
  "client_name": "Client A",
  "created_by": "User X",
  "labor_mode": "award",
  "margin_pct": 30,
  "monthly_price": 10000,
  "gross_profit": 4000,
  "net_profit": 3000,
  "profit_margin_pct": 30,
  "sites": [
    {
      "site_id": "...",
      "site_name": "Head Office",
      "tasks": [
        { "task_id": "...", "name": "Vacuum Carpets", "frequency_per_week": 5, "quantity": 1000, "shift": "Weekday", "monthly_hours": 86.6 },
        ...
      ]
    },
    ...
  ]
}
This allows the front-end to display or print the quote. The calculation may either be fetched from stored values or re-calculated on the fly. Since we plan to store the results, the API can just return stored numbers. Nonetheless, it will also fetch the task names, etc., via joins from the tasks table for completeness.
PUT /api/quotes/{id} – Update an existing quote. This could allow editing a quote’s details or scope after creation. For MVP, we might keep it read-only after creation (forcing users to create a new quote for changes, to preserve history). However, supporting an update is useful if a quote is in “Draft” status. This endpoint would accept a payload similar to POST and then update the quote record and associated line items (perhaps by deleting and reinserting scope items, or diffing and updating accordingly). This is a bit complex (maintaining consistency), so we might limit usage. We will include it for completeness but can restrict editing for now.
DELETE /api/quotes/{id} – Delete a quote. Marks a quote as deleted (or actually deletes). This might be used to remove test quotes or duplicates. We will implement it carefully with cascading delete of sites and items. In practice, quotes might rarely be deleted (maybe just archived), but an endpoint can exist for admin.
Configuration and Utilities APIs
GET /api/costing-configs – Get current costing configurations. Returns the list of labor cost configurations (or specifically identifies the active ones). This is used to populate the “Labor Plan” settings in the UI (e.g. showing current base wage, contractor rate, overhead %, etc.). Possibly we will mark one config as default for award and one for contractor.
PUT /api/costing-configs/{id} – Update costing config. Allows updating fields like base_hourly_rate, overhead_pct, etc. Only admin users would use this (e.g. when wages increase or new award rules apply). We could also allow creating a new config entry (POST) for versioning rather than editing in place, to preserve old configs for old quotes. In the UI, perhaps an admin can set a new default active config.
GET /api/print-quote/{id} – (Optional) Get a print-friendly format. This could return HTML or PDF of the quote for printing. Alternatively, we handle printing entirely on the client side, so this endpoint may not be necessary. If we wanted server-side PDF generation, an endpoint would trigger that.
GET /api/export/quotes – (Optional) Export quotes data. Could accept query (e.g. client or date range) and return a CSV or JSON of quote summaries. This might simply be handled on the client by calling GET /quotes and formatting, but a dedicated endpoint could streamline certain exports.
All API routes will return appropriate HTTP status codes (200 for success, 201 for created, 400 for bad input, 401/403 for unauthorized, etc.). Errors (validation issues, database errors) will be handled gracefully with messages. Note on Implementation: We will use Next.js API route handlers that leverage the Supabase client (server-side) to interact with the DB. We will wrap the multi-step quote creation in a transaction. If using Supabase JS library, one approach is to create a Postgres function to handle inserting quote, sites, and items, and call it via rpc() in one round-trip. Alternatively, use the Node Postgres client via Supabase to issue a BEGIN/COMMIT block. Ensuring atomicity is important for data consistency (so we don’t end up with half-inserted quotes if something fails midway). Security: We will enforce that the created_by field of quotes corresponds to the authenticated user. For read endpoints, if not an admin, the API will filter by created_by = user_id to ensure users only load their own quotes (if that is a requirement). If instead all internal users can see all, we may skip that filter. Regardless, all endpoints require login. Supabase Row-Level Security (RLS) policies can be configured on the quo​
ISSA.COM
nforce these access rules at the DB level as well. The combination of Next.js middleware (to check the user JWT) and DB RLS will secure the data.
Front-End Component Architecture
The front-end UI will be built in React (using Next.js pages
Front-End Component Architecture
The user interface will be built with React components and styled with Tailwind CSS, integrated into the Next.js application. The design will be intuitive and workflow-oriented, guiding the user from managing the task library to building a quote. Key parts of the interface include:
Task Database Page: A page (or tab) where the list of all cleaning tasks is displayed. This will likely be a 
ISSA.COM
​
ISSA.COM
, category, productivity rate, etc. Users with permission can add new tasks or edit existing o​
PAYCAT.COM.AU
​
PAYCAT.COM.AU
ms or modals for adding/editing tasks (fields for name, unit, productivity, etc.). It may include an import function (to load ISSA data initially, likely handled by developers or admin outside the UI). The Task list can be searchable or filterable by category for convenience.
Quote Creation Interface: This is the core UI for building a quote, which might be split into sub-sections or tabs for easier navigation. We propose a two-tab interface: Scope of Work and Labor Plan (as indicated by the provided mock-up). The user will typically:
Enter the high-level quote info (client name, etc.).
Define the Scope of Work – i.e., add sites and tasks.
Adjust the Labor Plan – i.e., set cost parameters or choose contractor vs award and profit targets.
Review the financial summary and save the quote.
【5†embed_image】The quoting interface includes a Scope of Work section where the user can add tasks for each site and immediately see the impact on costs and time. For example, the screenshot above shows input fields for a “Master Charge Rate” and “Master Cost Rate” at the top – these allow the user to set a default billing rate (charge to client per hour) and a default cost per hour, which can then be applied to all tasks. Below that is a table listing each task line with columns for Task, Category, Productivity, Area/Units, Frequency, Shift, Time per Service, Monthly Hours, Charge Rate, and Cost Rate. As tasks are added with their details, the system calculates the Time per Service and Monthly Hours automatically. A real-time Financial Summary panel (below the task table) displays metrics like Monthly Revenue, Gross Profit (before overhead & equipment), Net Profit (after all costs), and Profit Margin, as well as a breakdown of weekly, monthly, and annual figures for revenue and various costs. This dynamic feedback allows the user to adjust inputs (such as changing a task’s frequency or shifting it from a weekend to a weekday) and immediately see how the profits and costs change.
Scope of Work Component: Within the quote builder, the Scope of Work tab will contain UI elements for managing sites and their tasks. Users can add multiple sites – perhaps via an “Add Site” button which creates a new collapsible panel or section for that site. Within each site panel, there will be an “Add Task” functionality. Adding a task opens a row with a dropdown to select the task from the task library, input fields for area/quantity and frequency, and a dropdown for shift type. The UI will pull the selected task’s productivity rate to display (so the user knows the reference value). As soon as quantity and frequency are entered, the “Time per Service” and “Monthly Hours” for that line are calculated and displayed. The Charge Rate and Cost Rate columns for each line are populated based on either the global Master rates or specific overrides: if the user has not overridden them, they might all mirror the “Master” values (with cost rate auto-adjusting per shift for award mode). The user can override a line’s charge or cost if needed (e.g., click into the cell and edit it), in which case that particular line’s values will no longer follow the master default.
Labor Plan Component: In the quote interface, the Labor Plan tab allows configuration of the costing assumptions for the quote. Here the user can toggle between Award-based vs Contractor pricing modes. If Award is selected, the UI will show fields like “Base Hourly Wage”, “Casual Loading”, “Weekend Penalty”, “Holiday Penalty”, etc., pre-filled from the current Costing Config (and possibly not editable by a regular estimator if those are standardized – or they might be view-only). It will also show “Overhead %” and “Equipment $/hr” fields. If Contractor mode is selected, it will show “Contractor hourly rate” and still overhead/equipment (if those apply similarly). The user can adjust the profit target here as well – perhaps by specifying a desired Profit Margin % or by directly setting the “Charge Rate”. In the screenshot’s design, the “Master Charge Rate ($)” might correspond to setting a charge rate such that a certain margin is achieved given the cost. In practice, the UI might offer either: let the user input a margin % and auto-calc the necessary charge rate, or input a charge rate and derive margin. The Labor Plan tab basically summarizes all the financial inputs separate from the scope itself. Changes here (like increasing the base wage or overhead) will immediately reflect in the financial summary and potentially update the cost rate columns in the Scope table.
Real-time Calculations and Feedback: The React components for scope and labor plan will share state so that any change triggers a recalculation of the quote summary. We will use React state hooks or context to manage this shared state. For example, as the user edits a task’s frequency or toggles the contractor mode, the totals state is recalculated and the summary component is updated. This provides instantaneous feedback, which is crucial for the “what-if” scenario exploration. The calculation logic can run in the browser for responsiveness, using the same formulas as the back-end (we will ensure consistency by centralizing the formula in a utility module that can be used both client-side and server-side).
Quote Summary Display: As shown in the mock-up, a summary panel will be visible (probably fixed below the task list, or in a sidebar) showing key results: Monthly Revenue (the price to client), Gross Profit (before overhead and equipment costs), Net Profit (after all costs), and Profit Margin %. Additionally, a “Time-Based Financial Overview” can present weekly, monthly, annual breakdowns of revenue and cost. This summary is updated live. We will format currency values and percentages nicely (using perhaps a library or util for currency). Tailwind will be used to style these summary cards (e.g. making profits green if positive, etc., as in the screenshot where $0.00 and 0.0% are shown in green text).
Quote List Page: A page that lists saved quotes in a table or card format. Each entry might show Quote ID, client name, date, created by, and key figures (monthly revenue, profit margin). The user can click on a quote to view details (navigating to a Quote Detail page). This page helps users review past quotes. We can allow sorting or filtering by client or date for convenience. This page will fetch data via GET /api/quotes.
Quote Detail / Print View: When viewing an existing quote, we will present the information in a read-only format, suitable for printing or exporting. This could be the same interface as the creation view but with fields disabled, or a dedicated read-only layout. A “Print” button can trigger the browser’s print dialog with a print-optimized stylesheet. We will ensure a clean print layout (e.g. white background, all necessary data visible, pagination for multiple sites if needed). If needed, we could also implement a PDF download, but initially leveraging browser print is simpler. The detail view will show the breakdown by site and task, and the financial summary – essentially a formatted report of what was input and the resulting costs. This is the view that might be shared with management or kept on file.
Responsiveness and UX: The application will be primarily used on desktop by internal staff, so a desktop-first design is assumed. Tailwind will be used to create a responsive grid/table so that if needed it could be viewed on a tablet. We will use consistent ERP styling (colors, fonts) so the module feels integrated. Form inputs will have clear labels and possibly inline help (e.g. an info icon explaining what “Master Cost Rate” means, etc.). Validation feedback (e.g. if a required field is missing) will be shown to the user. We aim for short, logical forms – e.g., adding a task in the scope as one line rather than a multi-field dialog.
Under the hood, Next.js will serve these as a combination of pages and components:
We might have a Next.js page for /tasks (Task Database management), /quotes/new (New Quote builder), /quotes/[id] (Quote detail view), and /quotes (list).
Common components: TaskTable, QuoteForm, SiteSection, TaskLineItem, SummaryPanel, CostingForm (for labor plan inputs), etc., will be created to organize the UI. This modular approach means we can reuse a TaskLineItem component for each task row and it manages its own logic (e.g. calculating its time per service).
We will use local state for forms and possibly Next.js API for saving. For state management across the Scope and Labor Plan tabs, a React Context or lifting state up to the parent QuoteForm component will be done.
Calculation Engine Structure
The calculation engine is responsible for turning the input data (tasks with quantities and frequencies, labor rates, etc.) into the output metrics (hours, costs, profits). This logic will be implemented in a shared module (JavaScript/TypeScript functions) so it can be used both on the client (for instant UI updates) and on the server (for final save, or in case heavy calculations are needed server-side). Key Calculation Steps:
Per Task Time Calculation: For each scope item (task entry), compute the labor time required for one service:
If we have productivity_rate as units per hour (from the tasks DB) and a given quantity, then hours_per_service = quantity / productivity_rate.
Example: Task “Vacuum Carpets” with productivity 200 m²/hour, quantity 400 m² -> hours_per_service = 400/200 = 2.0 hours.
(If we stored minutes per unit, we’d do quantity * minutes_per_unit / 60 to get hours; it’s equivalent.)
This gives the Time per Service which is displayed in the UI.
Frequency to Monthly Factor: Determine how many times per month the task is done. If frequency was input as per week, we multiply by 4.33 (approx average weeks per month) to get per month. If frequency was per day (like daily weekdays = 5 per week), we could convert similarly (5 per week -> ~21.65 per month). Alternatively, if user inputs “monthly” we treat that as 1 per month (which is ~0.23 per week).
We will use a consistent conversion so that all tasks ultimately yield a monthly count of services. For exactness, we might base on per week and use 4.333 (which gives 52 weeks/year / 12).
Using the above example: 2.0 hours per service and frequency 5/week => services per month ≈ 21.65, so monthly_hours = 2.0 * 21.65 = 43.3 hours per month.
Aggregate Hours: Sum up the total monthly hours for all tasks in the quote. We can also sum per site if needed (e.g. to know hours per site). We will also sum by shift category:
e.g. total Weekday hours vs total Weekend hours vs Holiday hours in the quote. This is important for Award mode costing, since different hours will cost differently.
For example, if one site has 40 monthly hours of work on weekdays and another has 10 monthly hours on weekends, we know to cost 40 hours at base rate and 10 hours at weekend rate.
Labor Cost Calculation (Award mode): If labor_mode is award:
Start with the base hourly rate (from costing_config, e.g. $25/hr for a full-time Level1 or $31.25/hr for a casual including 25% loading).
Apply shift multipliers to calculate cost for each group of hours:
Weekday hours cost = hours_weekday * base_rate.
Weekend hours cost = hours_weekend * base_rate * weekend_multiplier. (If weekend_multiplier = 1.5, this effectively accounts for higher Saturday/Sunday pay. If different multipliers for Sat vs Sun were desired, we would refine by specific day, but currently one category.)
Holiday hours cost = hours_holiday * base_rate * holiday_multiplier (e.g. 2.5).
Sum these up to get total direct labor cost.
Add allowances if any are defined. For example, if we have an allowance per hour (or per shift), we could do total_allowance_cost = hourly_allowance_rate * total_hours, or if some allowances are per shift we’d need number of shifts. For simplicity, we might fold minor allowances into an effective base_rate or overhead. However, if we want to be precise: e.g., if each shift (day) a cleaner works has a $10 travel allowance and we estimate X shifts per month, that could be added. In early version, we may skip this complexity or handle it as part of overhead.
The result is the Labor Cost for the month. (This is essentially wages the company will pay its cleaners for this work.)
To illustrate: suppose base_rate = $30/hr (including casual loading), we calculated 50 hours/month on weekdays and 10 hours/month on weekends. If weekend multiplier is 1.5:
Weekday labor cost = 50 * $30 = $1500
Weekend labor cost = 10 * $30 * 1.5 = $450
Total labor = $1950. If overhead and equipment are zero and we charge say $3000, gross profit = $1050.
We also ensure to incorporate the standard loadings: e.g. the 25% casual loading can be baked into base_rate as mentioned, or if not, base_rate (for full-time) would be $25 and casual hours would be multiplied by 1.25 as well. We assume base_rate already includes whichever employment type is used (likely casual, since many cleaning staff are casual【15†L7-L15】).
Note: The Award also has rules for overtime (after 38 hours/week, etc.) and night loading (e.g. additional % for night shifts). These are beyond current scope. We assume the quote is structured to avoid overtime by distributing staff, and we treat any night work either as part of “weekday” (if after-hours cleaning on weekdays often has say 15% loading after 10pm, which we are not explicitly calculating). These could be future enhancements for more precision. For now, the main cost differentiators we handle are weekend and holiday work.
Labor Cost Calculation (Contractor mode): If labor_mode is contractor:
We have a flat contractor_hourly_rate from the config (say $45/hr that the subcontractor charges).
All hours regardless of shift are charged at this flat cost (the contractor presumably factors in any penalties into their flat rate or the contract is structured as fixed).
So, total labor cost = total_hours * contractor_rate.
(We can still categorize by shift for reporting if needed, but cost per hour remains the same across categories in this mode.)
Contractor mode typically does not involve allowances or loadings, since it’s an agreed flat fee per hour or per month. We assume per hour for simplicity.
Overhead and Equipment Costs: After labor cost is determined, we calculate overhead and equipment:
Overhead cost = overhead_pct * labor_cost (if overhead_pct is provided, e.g. 10%). This treats overhead as proportional to labor. Alternatively, some might compute overhead on revenue, but we will use labor as the base to ensure we cover internal cost overhead.
Equipment cost = equipment_cost_per_hour * total_hours. This assumes a linear relationship between hours of cleaning and usage of equipment/supplies. For example, if total_hours = 60 and equipment_cost_per_hour = $1.50, then equipment_cost = $90. (If we had different equipment for different tasks, we could refine by task, but a blended rate is fine for now.)
These costs are summed with labor cost to get Total Cost of delivering the service.
Pricing (Revenue) and Profit: The module can determine a selling price (what we charge the client) based on either a desired profit margin or a specified charge rate:
If user enters a target profit margin %, the system will compute the required monthly price. For example, if total cost is $2000 and target margin is 30%, that means net profit should be 30% of price. To achieve that, price = cost / (1 - 0.30) = ~$2857 in order to have $857 profit which is 30%. We will do this calculation when margin is input.
If user directly inputs a Master Charge Rate ($/hr) (as in the UI), we can compute revenue = total_hours * charge_rate. For instance, if total_hours = 60 and charge_rate = $60/hr, the monthly revenue = $3600. Then we can derive what margin that corresponds to given the cost.
The UI likely ties these together: adjusting margin slider updates the charge rate field, and vice versa, so the user can use whichever they prefer. The final chosen values will be used in the saved quote.
Once monthly revenue is determined, we compute Gross Profit = Revenue - Labor Cost (before adding overhead & equipment) and Net Profit = Revenue - (Labor + Overhead + Equipment). In other words, gross profit is profit before overhead/equipment, and net profit is after all costs. In our above example, if revenue $3000, labor $1950, overhead $0, equipment $0, gross profit = $1050, net profit = $1050. If we had overhead $100 and equipment $50, then gross profit still $1050, net profit = $1050 - $150 = $900.
Profit Margin % = (Net Profit / Revenue) * 100. E.g. $900/$3000 = 30%. This is shown in the summary.
Weekly/Annual Projections: These are straightforward conversions:
Weekly revenue = monthly revenue / 4.333, weekly labor cost = monthly labor / 4.333, etc.
Annual revenue = monthly revenue * 12, etc.
We’ll display those as secondary info. (Alternatively, compute from total hours per year, but since frequencies might not be perfectly monthly, using the conversion is fine.)
The calculation engine will be carefully tested with known scenarios to ensure accuracy. For example, we can cross-verify that if a single task’s data is put in, the calculations align with manual computations or known benchmarks. We will also test edge cases like zero frequencies, or all tasks on public holidays, etc., to make sure formulae hold up. Implementation: We will create a module, say quoteCalculator.js, that exports functions such as calculateQuote(quoteInput, costingConfig) -> quoteResult. This function can be used in the front-end to update state and in the backend in the POST /api/quotes to double-check and populate the stored values. Internally, it will likely break the process into sub-calculations:
calculateTaskHours(taskItem, taskDefinition) -> { hours_per_service, monthly_hours }
calculateLaborCost(hoursBreakdown, rates) -> laborCost
etc., for clarity.
By having this centralized, we avoid mismatches between what the user sees and what gets saved. On save, we will re-run the calculation with the same inputs to guard against any client-side glitch, and then store the results. We will document the formulas (even possibly show them in a help section for transparency, since some users may want to understand how the numbers are derived). In fact, citing an industry formula: “Cleaning time can be calculated as the amount of square footage to be cleaned divided by the production rate per hour, multiplied by 60 to get minutes”【13†L516-L520】 – our engine essentially automates this for each task and sums them up.
Integration with Supabase (Data & Auth)
Integrating with Supabase will primarily involve using it as our database and using its authentication mechanism to identify users. Key integration points and plans include:
Database (Postgres): All the schema described will be created in Supabase. We will use migration scripts or the Supabase UI to define the tables, relations, and constraints. Supabase being a PostgreSQL database means we can rely on SQL constraints (foreign keys between quotes, sites, tasks, etc., to maintain data integrity).
Row Level Security (RLS): Given Supabase’s security model, we will enable RLS on sensitive tables like quotes and related tables. Initially, if we decide that only the creator of a quote can view/edit it, we will write policies such that:
quotes: allow select/update/delete to users where quotes.created_by = auth.uid().
allow insert to any authenticated (with created_by set to their uid via a function or check).
quote_sites and quote_scope_items: likely will be manipulated only through our API, but we can add policies that join through the quote -> ensure the quote’s created_by matches the auth user.
If all internal users are allowed to see each other’s quotes, we might relax these rules or not enable RLS (and rely on front-end to hide unauthorized actions). But best practice is to enforce minimal rights at DB level too.
Supabase Auth: We will utilize Supabase’s built-in email/password (or other) authentication. The Next.js front-end will use the Supabase JS client to allow login. Once logged in, a user session and JWT are available, which will be passed to API calls. We can use Supabase’s middleware or manually verify the JWT in Next.js API routes to get the user’s identity (Supabase provides helpers to get the user from the auth header). This way, the API knows which user is making the request and can apply the logic accordingly (e.g. attach created_by on new quotes).
Supabase Client usage: For data fetches that are simple (like GET tasks, GET quotes list), we have two choices:
Use Next.js API routes as an intermediary (the front-end calls our API which then calls Supabase).
Or call Supabase directly from the front-end (using the JS client library).
We will adopt primarily the Next.js API approach for operations that require business logic (like creating quotes with multiple inserts and calculation). For simpler fetches (like pulling the task list or maybe pulling one quote for display), using the Supabase client directly in a React component is possible and can reduce latency (Supabase can return data directly to client). However, for consistency and to centralize access control, we may still route everything through our API. This also allows easily switching to server-side rendering if needed (Next.js getServerSideProps could fetch data securely).
Supabase Storage: Not heavily used in this module, since we are not storing files or images from users. One possible use could be storing an uploaded spreadsheet of tasks, but that’s an admin action and not needed in normal operations.
Supabase Functions (RPC): If the calculation or insertion logic becomes complex to handle in multiple round-trips, we might create a stored procedure on the database to, for example, insert a quote and all its sub-records in one go. This RPC could also enforce any additional constraints. It’s an optional optimization. Given our control in Next.js, we may simply use the server-side transaction approach as described.
Real-time: Supabase offers realtime subscriptions on table changes. We likely don’t need realtime sync for this module (multiple users editing the same quote concurrently is unlikely, and not in scope). So we will not enable realtime features here. One could imagine a scenario where an admin could watch quotes being built in realtime, but that’s not a requirement.
Performance considerations: The dataset sizes are not huge (task library maybe a few hundred tasks maximum, quotes maybe thousands over years). Queries are straightforward (indexed by IDs, etc.). Supabase can handle these easily. We will ensure to index foreign keys (which Postgres does by default for PKs) so that looking up tasks or joining tables is efficient. If we allow searching quotes by client, an index on client_name might be useful for partial matches, or we could integrate with a proper search solution later if needed (not likely necessary initially).
Deployment: Since this is part of an existing ERP, the Next.js app is presumably already deployed. We just need to update environment configuration for Supabase (URL, anon/service keys) and ensure the front-end is allowed to talk to it. Supabase will act as the single source of truth for this module’s data.
Backups and Migrations: Using Supabase means our data is stored safely in the cloud with regular backups. We will maintain migration scripts for the new tables (possibly using a tool like Supabase Migrations or Prisma if used in the project). This ensures the schema can be reproduced and versioned.
In summary, Supabase provides the back-end foundation: user auth to secure the module, and Postgres to reliably store all quote data. The front-end and API will use Supabase’s libraries and features to implement the module’s functionality in a secure, consistent manner.
Future Enhancements and Wishlist Integration
Looking forward, there are several enhancements and integrations planned (or envisioned) for the quoting module to increase its intelligence and utility:
AI Assistant for Quoting: Integrating an AI (perhaps via OpenAI GPT models or similar) to assist the user during quote creation. For example, the AI could help generate a list of recommended tasks and frequencies based on a description of a site. The user might input the building type and size, and an AI could suggest a scope of work (tasks with estimated frequencies) as a starting point. This could expedite the quoting process for new scenarios. Another use: the AI could analyze a completed quote and highlight anomalies or suggest optimizations (e.g. “Task X has very high frequency, which is driving labor cost up, consider if it’s needed so often”). Such an assistant would be integrated into the UI perhaps as a sidebar chat or a “Auto-generate scope” button. Data from the tasks library and historical quotes would train the suggestions. We’d ensure the architecture can accommodate calling out to an AI API and that the data (task definitions, etc.) can be fed as context.
Auto-Optimization Features: Building on scenario analysis, we can allow the system to automatically adjust certain parameters to meet goals. One idea is a “Optimize for Margin” tool – the user sets a desired profit margin and the system iteratively adjusts the charge rate (or suggests where to reduce costs) to hit that margin. Another idea is optimizing task scheduling: for instance, if a quote currently has some tasks on weekends, the system could calculate the cost difference if those tasks were moved to weekdays (or done during normal hours) – essentially a built-in what-if analyzer that might say “If all tasks were done on weekdays, profit would increase to X (assuming it’s feasible)”. In the future, if integrated with workforce data, it could also optimize how many staff or shifts are needed to cover the hours in the most cost-effective way (this toes into workforce management, which is out-of-scope now, but later could ensure the quote is not just cost-accurate but also operationally feasible). The calculation engine is being designed in a modular way, so adding optimization routines or goal-seek functions is feasible.
Historical Data Analysis: Over time, the company will accumulate a lot of quote data. Analyzing this can yield insights. We plan to add dashboards or reports for:
Win/Loss tracking: (If we integrate quote outcomes) – e.g. flag which quotes turned into actual contracts and compare estimated vs actual costs later on.
Pricing consistency: Ensuring similar clients or sites are quoted with similar margins – a report could list profit margins of all quotes by type.
Productivity calibration: By comparing quotes to actual labor usage (if later integrated with timesheets), the system could adjust productivity rates. For example, if every quote using a certain task ended up with overtime, maybe the productivity was overestimated.
For now, a simpler historical analysis might be an export of all quotes to CSV for analysis in Excel. In-app, we might show trends like average profit margin on all quotes this quarter, or distribution of labor vs overhead costs.
We will keep all the detailed data (down to each task line) which means in the future we can do granular analysis, such as “What tasks contribute most to cost across all quotes” or “which client segments demand more weekend work (and thus incur higher costs)”.
Integration with Other ERP Modules: While this quoting tool is standalone now, in the future it could connect to:
CRM/Contracts: If a quote is accepted by the client, the data could flow into a contract management system or a scheduling system. For example, generate a contract document or at least mark the quote as accepted and lock it. This would involve linking the quote to a client record (if not already) and possibly storing a status.
Billing: If later the ERP wants to use these quotes for billing, an integration could create a recurring invoice template from the quote (monthly charge).
Workforce Management: The quote could inform the operations team about needed staffing. For instance, if a quote has 160 hours/month of work, that’s roughly 40 hours/week – one full-time cleaner required. The module could eventually provide a breakdown like “Requires 1.0 FTE on weekdays and 0.2 FTE on weekends” as guidance. This overlaps with the concept of a “Labor Plan” possibly showing how many staff or shifts are needed. In the current design, we stop at hours and costs, but as a wishlist item, automatically translating hours into headcount (considering an employee’s workable hours) is valuable.
We have kept the schema and structure extensible for these – e.g., adding a field in quotes for status or linking to a contract ID in future won’t require major overhaul.
Refining Cost Calculations: Future award changes (like if the Award gets updated rates or new categories) will be handled by updating the costing configs. We might also incorporate multiple labor grades (e.g. Level 1 cleaner vs Level 3 supervisor) if needed for different tasks (some specialized tasks might use a higher-paid staff). This could mean each task in the library could have an associated “grade” or an override cost multiplier. The current design with override rates per task line can already accommodate special cases. A more structured approach could be to allow selecting the staff level on a task. This is not in MVP, but possible later.
UI Enhancements: Over time, we expect to improve the user experience with features like:
Templates or cloning: the ability to copy a previous quote or use a template for common contract types (e.g. an office of X size template) and then adjust specifics. This saves time on repetitive work.
Validation rules: e.g. warn if profit margin is below a threshold or if a frequency seems unusually high.
Multi-currency or multi-region support if the business expands (not immediately relevant since this is very tailored to Australian context and AUD).
All these wishlist items have been considered in the architecture so far. We have structured data in a normalized way that is easy to extend, and used a modular approach (both in code and UI) that will accommodate additional logic. The separation of concerns (task data vs quote data vs cost config) means each can evolve: for instance, hooking in an AI only needs read access to task library and maybe past quotes; optimizing schedules could use the structured breakdown of hours by shift. In conclusion, the Commercial Cleaning Quoting Module will provide a robust foundation for generating cleaning service quotes efficiently and accurately. It leverages standardized data (ISSA cleaning times【13†L480-L488】) and enforces consistency through an integrated calculation engine, while also giving users the flexibility to adjust scenarios. With a solid technical design in place, the module can be built and then iteratively enhanced with advanced features like AI guidance and deeper analytics, ensuring it remains a valuable tool for the company’s operations and sales teams. All outputs will be internally used to drive business decisions, and the module will serve as a single source of truth for quoting parameters and results, improving both the speed and accuracy of the company's commercial cleaning proposals. Sources:
ISSA Cleaning Times (benchmark production rates for cleaning tasks)【13†L480-L488】【13†L516-L520】
Fair Work Australia – Cleaning Services Award MA000022 (wage rates, loadings & penalties)【15†L7-L15】【16†L25-L32】
Technical Specification – Commercial Cleaning Quoting Module
Overview and Scope
The Commercial Cleaning Quoting Module is an internal web-based tool for generating detailed cleaning service quotes as part of the company’s ERP system. It enables users (estimators) to build multi-site cleaning scopes of work with accurate time and cost estimates, using industry-standard productivity rates. Key features of the module include:
Task Database Management: Maintain a library of cleaning tasks with standard productivity rates (sourced from ISSA guidelines, adjusted ~20% for local Australian conditions【13†L493-L498】). This task database serves as the basis for all time calculations in quotes.
Multi-Site Quote Builder: Create quotes that cover one or multiple sites. For each site, users can specify the tasks to be performed, the frequency of each task, the area or quantity, and the shift type (weekday, weekend, or public holiday) for performing that task.
Productivity-Based Calculations: Automatically calculate the labor hours required for each task based on the task’s productivity rate and the specified area/units and frequency【13†L480-L488】【13†L516-L520】. Roll these up into total hours per site and for the entire quote.
Costing and Pricing Engine: Support two labor cost modes – (1) Award-based (using the Australian Cleaning Services Award MA000022 rules for wages, including an​

gs, weekend/public holiday penalty rates, and typical allowances) and (2) Contractor rate (a flat hourly labor cost). The engine applies overhead costs, equipment depreciation costs, and profit margin to produce final pricing.
Financial Metrics: Present key financial outcomes for the quote, including Monthly Recurring Revenue, Gross Profit (before overhead & equipment costs), Net Profit (after all costs), and Profit Margin. These are derived from the detailed cost buildup. Additionally, provide a breakdown of revenue and cost on weekly, monthly, and annual bases for transparency.
Scenario Analysis (“What-If”): Allow users to adjust parameters on the fly – for example, tweak the target profit margin or hourly rates, change task frequencies or shift assignments – and immediately see updated quotes. This helps in exploring scenarios such as “What if we require a 5% higher margin?” or “What if weekend tasks are moved to weekdays?”.
Quote Records and Export: Every generated quote is saved in the system, with the responsible user’s name and the client name recorded (both are mandatory inputs). Users can review past quotes, export summary data (as CSV or JSON), or print a formatted quote summary for sharing with stakeholders.
Out of Scope: This quoting module focuses solely on estimating the labor and service costs for cleaning contracts. It is not intended to handle downstream contract approval, billing/invoicing, or workforce scheduling/management of staff. Those functions are either handled by other ERP modules or future enhancements. The quote outputs are for internal use to inform pricing proposals, not for automated contract generation. The module will be built with the existing technology stack: Next.js (React) for the front-end UI, Tailwind CSS for styling, and Supabase (PostgreSQL) for data storage (taking advantage of Supabase’s hosted database and authentication). The following sections detail the database design, API endpoints, front-end architecture, calculation engine, and integration considerations.
Database Schema
The application will introduce several new tables in the Supabase (Postgres) database. Below is the schema design with tables and key fields. Relations use primary keys (IDs) to link records, and foreign keys ensure referential integrity. All timestamps (created_at, updated_at) are omitted for brevity but will be included for audit trail on each table.
Users
The system will use the ERP’s existing user accounts (likely managed via Supabase Auth). We assume a users table (or Supabase’s built-in auth.users) exists. Each quote will reference the user who created it. Minimal user info needed for this module is the user’s unique ID and name.
user_id (PK): Unique identifier for the user (UUID as provided by Supabase Auth).
name: User’s full name (for display on quotes).
email: (If needed, for notification or record; might already exist in auth).
Integration note: We will rely on Supabase Auth for user management, so the quoting module will use the authenticated user’s ID from the session for any create/read operations. No separate password handling is needed here.
Tasks
The tasks table stores the library of cleaning tasks and their standard productivity rates. This is seeded initially with data from the ISSA Cleaning Times reference, with a 20% time adjustment to reflect Australian conditions (since ISSA figures are benchmarks that often need local adjustment【13†L493-L498】). Users with proper permission can manage (add/edit) these tasks as needed over time.
task_id (PK): Unique ID for the task (UUID or serial).
name: Descriptive name of the task (e.g. "Vacuum Carpets", "Mop Hard Floors").
category: Category or group the task belongs to (for organizational purposes, e.g. "Floor Care", "Restrooms"). Categories could be free text or a reference to a categories table. (For now, a text field is sufficient; it helps group tasks in the UI.)
unit_type: The unit of measure for the task productivity, indicating what the quantity refers to. Examples: "sqm" (square meters), "sqft", "each" (per item), "fixture", etc. This helps the UI prompt the correct input (area vs count).
productivity_rate: The standard productivity rate of the task. This can be stored as output per hour by one worker. For example, if a worker can clean 100 square meters of carpet in 1 hour, the productivity_rate = 100 (sqm/hour). If a task is measured per item (e.g. 10 fixtures/hour), store that number. All rates in the DB will already include the 20% adjustment for Australian conditions. (Alternatively, store the base ISSA rate and a separate adjustment factor, but applying the factor upfront simplifies usage.)
baseline_minutes_per_unit (optional): Instead of or in addition to productivity_rate, we might store how many minutes one unit takes. This can be derived (since minutes per unit = 60 / productivity_rate for area tasks). For example, if productivity_rate is 100 sqm/hour, minutes_per_unit for 1 sqm = 0.6 minutes. Storing one or the other is sufficient. We will use productivity_rate for calculations.
description (optional): Longer text describing the task or its scope (if needed for clarity).
Example: A task "Mop Tile Floor" might have unit_type "sqm" and productivity_rate = 300, meaning one cleaner can mop 300 m² per hour on average. A task "Clean Toilet Fixture" might have unit_type "each" and productivity_rate = 20 (fixtures/hour). These values come from ISSA’s guidelines and can be edited if on-site studies show different performance.
Shift Types
The shifts table defines the categories of shift timing that affect labor cost rates under award-based costing. We will define three shift types as per requirements: weekday, weekend, and public holiday. Each shift type entry carries the multiplier or loading to apply on top of base hourly wages (per the Cleaning Award MA000022). This allows the cost calculation to adjust wages for work done on weekends or holidays.
shift_id (PK): Unique ID for the shift type.
name: Name of shift category – e.g. "Weekday", "Weekend", "Public Holiday".
award_multiplier: The pay rate multiplier relative to the base wage, for award-based costing. For example, Weekday might be 1.0 (base rate), Weekend might be 1.5 (150% pay), Public Holiday 2.5 (250% pay). These are approximate; exact Award rules can be more complex (Sat vs Sun differ, etc.), but we will use a representative multiplier for simplicity. (We assume “Weekend” covers both Saturday and Sunday with a single multiplier. In future this could be split if needed.)
description: (Optional) Description of the shift or any notes (e.g. “Use 1.5× for any weekend day work as a simplification of Sat/Sun penalties”).
Rationale: The Award MA000022 specifies penalty rates such as 150% for Saturdays and 200% for Sundays for full-time/part-time employees (casuals incur an additional loading)【17†L97-L105】. We will use a single weekend multiplier (likely ~1.5 or 1.75) to cover typical weekend cost, recognizing Sunday is higher. For public holidays, double-time-and-a-half (2.5×) is common【17†L103-L110】. These multipliers will be used to inflate the base hourly wage for any hours classified in that shift.
Costing Configs
The costing_configs table stores parameters for the cost calculations, particularly labor rates and overhead settings. It allows the system to support both Award-based and Contractor costing modes, and can be extended or updated as rates change. We anticipate at least two records in this table (one for each mode), or possibly multiple versions over time (if wages are updated annually, new records could be added with effective dates). Fields for a costing_config may include:
config_id (PK): Unique ID for the costing configuration.
name: Name/label of the configuration (e.g. "Award 2025 Rates", "Contractor Rate Std").
mode: "award" or "contractor" – identifies which labor costing approach this config represents.
base_hourly_rate: The base hourly wage rate. For award mode, this would correspond to the normal hourly pay for a cleaner (e.g. the Level 1 Cleaning Service Employee rate). For contractor mode, this could be left null or used similarly (though contractor mode will primarily use the flat rate field below).
casual_loading_pct: (Award mode) The additional percentage for casual employees. The Award specifies 25% loading for casuals【15†L7-L15】. If the company’s quoting assumes use of casual labor, this can be 25. If assuming full-time, this could be 0. (We can incorporate this into the base_rate if we assume one or the other to simplify real-time calc.)
award_allowances_per_hour: (Award mode, optional) Any average allowance cost per hour of work. This could factor in things like uniform, laundry, travel time allowances, etc., averaged out. For simplicity this might be a small fixed addition (e.g. $1/hour) to cover typical allowances. (Alternatively, we handle a fixed cost per shift separately, but for quoting we’ll likely roll minor allowances into an hourly cost adder.)
contractor_hourly_rate: (Contractor mode) The flat hourly cost rate if using subcontractors. This is what the contractor charges us per hour of work (e.g. $45/hour flat, regardless of weekend or not, since the contractor handles their own penalties).
overhead_pct: Percentage of direct labor cost to add as overhead. This accounts for indirect costs (management, insurance, admin) associated with providing the service. For example, 15% overhead means we will add 15% of labor+contractor costs as an overhead cost.
equipment_cost_per_hour: A rate (in $) to represent equipment depreciation and supplies per hour of cleaning. For example, $2/hour might be added to cover the wear-and-tear and consumables (chemicals, tools) used. This could also be represented as a percentage of labor, but a per-hour flat rate is straightforward.
default_profit_margin_pct: (Optional) A default profit margin target. This might be used as an initial suggestion in quotes (e.g. aim for 30% margin). Profit margin in quoting is handled by setting the charge rate to achieve the desired margin.
Only certain fields are used depending on the mode. For instance, in award mode, we use base_rate, casual_loading, etc., while in contractor mode we primarily use contractor_hourly_rate. The overhead and equipment fields are applicable to both modes. The system can come pre-configured with known Award rates (e.g. base rate $25/hour for Level 1, casual loading 25%, etc.) and a default contractor rate if applicable. Admin users should be able to update this table as wages or cost assumptions change over time (ensuring quotes stay up-to-date with current costs).
Quotes
The quotes table is the parent record for each saved quote. It contains high-level information about the quote and relationships to associated sites and scope items. Each quote represents a proposal for recurring cleaning services (usually priced per month).
quote_id (PK): Unique identifier for the quote.
client_name: Name of the client or organization the quote is for. (This is a required field input by the user when creating the quote.) It may just be a text field here, or potentially a foreign key to a clients table if the ERP has one. In this module we will treat it as text input.
created_by: Reference to user_id of the Users table – the user who created the quote. This is recorded automatically to track accountability.
created_at: Timestamp when the quote was created.
labor_mode: The labor costing mode used for this quote ("award" or "contractor"). This determines which costing method was applied in calculations.
config_id: (Optional) Reference to the costing_configs used. If we maintain historical configs, this links the quote to the specific costing assumptions at that time. Alternatively, we might store some of the cost parameters directly on the quote to freeze them (see below).
margin_pct: The profit margin percentage applied on this quote (if applicable). For instance, if the user targeted a 20% profit margin, this would be 20.0. This helps record the pricing strategy.
monthly_price: The total monthly recurring price quoted to the client (Revenu​
PAYCAT.COM.AU
n be stored for quick reference, even though it can be derived from details.
gross_profit: (Optional, can be derived) Gross profit dollar amount = monthly_price - labor_cost (before overhead/equipment).
net_profit: (Optional) Net profit dollar amount = monthly_price - (labor_cost + overhead_cost + equipment_cost).
profit_margin_pct: (Optional, can be derived) Profit margin = net_profit / monthly_price * 100%.
status: (Optional) Status of the quote (e.g. “Draft”, “Finalized”, “Accepted”, etc.). Initially, all quotes might just be considered final once saved. We might include this for future workflow.
Note: Storing the calculated financial results (price, profits) redundantly in the quotes table can be helpful to preserve a snapshot of what was quoted. This is especially important if cost inputs (like wage rates) change later – we don’t want historical quotes to be recalculated with new rates. By linking to a specific config_id or storing the numbers, we ensure the quote remains as originally given. We will implement either approach: link to a dated config or save the computed cost rates. For example, we might store effective_hourly_cost_rate on the quote if using contractor mode (so we know which rate was used), or effective_base_rate and multipliers if award mode. This level of detail ensures fidelity of historical data (and could aid future analysis).
Sites (Quote Sites)
The quote_sites table represents individual site locations included in a multi-site quote. Each quote can have one or more sites. If a quote only has one site, there will be one entry here. We separate sites to allow per-site breakdown of tasks and possibly to show per-site subtotals in the future.
site_id (PK): Unique identifier for the site entry (could be auto-generated).
quote_id (FK -> quotes.quote_id): The quote to which this site belongs.
site_name: Name or identifier for the site. This could be a location name (e.g. “Head Office”, “Warehouse 2”, “Melbourne Campus Building A”). The user will input this when adding a site to the quote.
site_address: (Optional) Physical address of the site, if relevant for reference. Not strictly needed for quoting calculations, but useful for the record or print-out.
notes: (Optional) Any additional notes about the site (e.g. “24/7 operation, no cleaning on Sundays” – if relevant to scope).
In many cases, the site_name is sufficient to distinguish sites in the quote. The site table mainly groups the task scope items (described next) and could be used later to integrate with a client/site database if needed.
Quote Scope Items (Tasks per Site)
The quote_scope_items table (or simply quote_tasks) contains the detailed line items of the scope of work for each site in the quote. Each record represents a specific task being performed at a specific site with a given frequency and workload. This is essentially the heart of the quote where all the input variables are captured.
scope_item_id (PK): Unique ID for this scope line item.
quote_id (FK -> quotes.quote_id): Reference to the parent quote.
site_id (FK -> quote_sites.site_id): Reference to the site within that quote where this task will be performed.
task_id (FK -> tasks.task_id): Reference to the task being performed (to pull in the productivity rate and unit).
frequency: The frequency of service for this task. This can be expressed in terms of occurrences per week (or per month). We will allow common inputs like “daily”, “weekly”, “monthly” in the UI, but store a numeric value. For storage, one approach is:
frequency_per_week (decimal): e.g. 5 for daily weekdays (5x per week), 7 for daily including weekends, 1 for weekly, 0.5 for biweekly (every 2 weeks, which is 0.5/week), 0.23 for monthly (approx 1 per 4.33 weeks).
Alternatively, store two fields: frequency_count and frequency_unit (where unit can be "per week", "per month", etc.). For simplicity, we use a normalized per-week value to facilitate calculations. We will interpret this appropriately (in calculations we convert weekly freq to monthly by multiplying by ~4.33).
quantity: The quantity of work for this task at this site. The meaning of this number depends on the task’s unit:
If the task is area-based (unit_type = sqm or sqft), this field is the total area to be cleaned each time (e.g. 500 m² of carpet to vacuum at the site).
If the task is item-based (unit_type = each, fixture, etc.), this is the count of items (e.g. 10 trash bins to empty, 15 fixtures to clean).
The UI label will adapt (showing “Area (sqm)” or “Units” accordingly) to guide input.
shift_id (FK -> shifts.shift_id): The shift category in which this task will typically be performed at this site. For example, a task might be scheduled during regular weekdays (shift_id for Weekday), or perhaps on weekends (shift_id for Weekend) if that task is only done during off-hours or if the facility is cleaned on weekends. This selection drives the labor cost multiplier in award mode.
time_per_service: (Optional, calculated) The estimated labor time required per service occurrence of this task (in hours). This is derived from quantity and task productivity. For example, if quantity is 500 m² and task productivity_rate is 250 m²/hour, then time_per_service = 2.0 hours. This is stored either for convenience or calculated on the fly each time.
monthly_hours: (Optional, calculated) The total labor hours per month for this task. This would be time_per_service * number_of_services_per_month. If frequency_per_week i​
ISSA.COM
ly services ≈ freq_per_week * 4.33. Using the above example, if vacuuming (500 m², 2 hours each service) is done 5 times a week, monthly_hours ≈ 2 * (5 * 4.33) ≈ 43.3 hours/month.
cost_rate_override: (Optional) A custom labor cost rate to use for this task line (per hour), overriding the default from the costing config. Normally, all tasks on a quote share the same underlying labor cost assumptions. But in special cases, a user might want to adjust a particular task’s cost. For example, if a highly specialized task is subcontracted separately at a different rate. This field can be null to indicate use standard calculation, or if set, that rate will be used for cost calculations for this line.
charge_rate_override: (Optional) A custom charge rate (price per hour) to the client for this specific task, overriding the general pricing. Usually not needed (generally we price all hours uniformly), but this could allow special cases (e.g. charging a premium for high-difficulty tasks or a discount for simple tasks). If null, the module will assume a standard charge rate or a global margin across all tasks.
When a quote is finalized and saved, the system will iterate through these scope items to calculate totals. We may choose to store the computed totals in the quote (as above). The detail records themselves (quote_scope_items) contain all info needed to recompute if necessary. Relationships: quotes -> quote_sites is one-to-many. quote_sites -> quote_scope_items is one-to-many. We ensure cascading deletes: if a quote is deleted, all its sites and scope items should delete (or be archived) as well. Deleting a task from the tasks library should probably be prevented if it’s used in any quote_scope_items (to preserve historical record integrity). Instead, tasks can be marked inactive if needed. Database Example: After a user creates a quote for “Client A” with 2 sites, each with several tasks, the tables might have entries like:
quotes: 1 record (Client A, created_by User X, labor_mode = "award", margin_pct = 30, monthly_price = $10,000, etc.)
quote_sites: 2 records (e.g. Site 1 = "Headquarters", Site 2 = "Warehouse")
quote_scope_items: multiple records, e.g.
(quote_id -> Quote A, site_id -> HQ, task = Vacuum Carpets, frequency_per_week 5, qty 1000 sqm, shift = Weekday),
(quote_id -> Quote A, site_id -> HQ, task = Mop Floors, frequency 5, qty 800 sqm, shift = Weekday),
(quote_id -> Quote A, site_id -> HQ, task = Sanitize Restrooms, frequency 3, qty 10 fixtures, shift = Weekday),
(quote_id -> Quote A, site_id -> Warehouse, task = Vacuum Carpets, freq 3, qty 500 sqm, shift = Weekend),
etc.
This structure is flexible and normalized. We can easily query, for example, all tasks for a given quote (join quote_scope_items with tasks), or the total hours per site, etc.
API Endpoints and Structure
We will implement a set of RESTful API endpoints (within Next.js API routes) to allow the front-end to interact with this data and perform operations. All endpoints will require an authenticated user (the system will check the Supabase auth session or JWT). Where appropriate, authorization checks will ensure users only access their own data (if quotes are private per user) or are limited by role. In an internal company context, it might be acceptable that all authorized users see all quotes; this can be configured as needed. Below are the primary endpoints:
Task Management APIs
GET /api/tasks – List all tasks. Returns a JSON array of task objects from the tasks table (id, name, category, unit_type, productivity_rate, etc). Used to populate task dropdowns or for viewing the task library. Supports query filters or pagination if the task list is large (though typically manageable).
POST /api/tasks – Create a new task. Accepts JSON body with task details (name, category, unit_type, base productivity, etc). This will insert a new record into the tasks table. Only authorized users (e.g. admin or estimator role) can add tasks. This could be used to add custom tasks or adjust the library beyond the ISSA-imported ones.
PUT /api/tasks/{id} – Update an existing task. Allows editing fields of a task (e.g. adjust the productivity_rate or name). This might be restricted if the task is in use by quotes (to avoid retroactively affecting past quotes’ calculations). A safe approach is to allow edits for future use but not recalc old quotes, as those have stored values. We will document that historical quotes aren’t automatically updated by changing task rates.
DELETE /api/tasks/{id} – Remove a task. This may be either disallowed or implemented as a “soft delete” (marking the task inactive) if the task is referenced in any quote. We likely won’t truly delete tasks that are in use. For now, we can omit implementing delete, or allow it only for tasks with no associated quote items. (An alternative is to have an active flag in tasks table and simply filter out inactive ones in GET.)
(Note: Instead of building a custom import endpoint for ISSA data, we will import the provided Excel offline and populate the tasks table as an initial migration/seed. If needed, an admin-only endpoint or script can be created to import tasks in bulk from a CSV/Excel. This is a one-time setup task and not part of regular user operations.)
Quoting (Scope) APIs
POST /api/quotes – Create a new quote. This is called when the user finalizes a quote in the UI. The payload will include the quote details: client name, an array of sites, and the scope items for each site, as well as the chosen costing mode and margin. For example, the JSON might look like:
json
Copy
Edit
{
  "client_name": "Client A",
  "labor_mode": "award",
  "margin_pct": 30,
  "sites": [
    {
      "site_name": "Head Office",
      "tasks": [
        { "task_id": "...", "frequency_per_week": 5, "quantity": 1000, "shift_id": "weekday" },
        { "task_id": "...", "frequency_per_week": 5, "quantity": 800, "shift_id": "weekday" },
        { "task_id": "...", "frequency_per_week": 3, "quantity": 10,  "shift_id": "weekday" }
      ]
    },
    {
      "site_name": "Warehouse",
      "tasks": [
        { "task_id": "...", "frequency_per_week": 3, "quantity": 500, "shift_id": "weekend" }
      ]
    }
  ]
}
The server handler will:
Validate the data (all required fields present, frequencies and quantities are positive, etc.).
Perform the quote calculations (using the calculation engine described later) to compute the totals (monthly hours, costs, price, profit, etc).
Insert a new quote record (quotes table) with basic info (client_name, user, mode, margin, and computed totals).
Insert the site records (quote_sites table) for each site.
Insert all scope items (quote_scope_items table) linked to those sites.
If all inserts succeed, return a success response with the new quote_id and perhaps the computed summary. This operation should ideally be atomic. We will use a database transaction (via Supabase or a single stored procedure call) to ensure that all related inserts succeed or all fail (to avoid partial quotes).
GET /api/quotes – List quotes. Returns a list of quotes accessible to the user. Likely returns a summary (quote_id, client_name, created_by, date, total price, profit margin). If the system is multi-user, a regular user might see only their own quotes, while an admin could see all. We can implement a filter by user = current user for non-admin roles. Query parameters could allow filtering by date range or client.
GET /api/quotes/{id} – Get quote details. Returns the full details of a specific quote, including its sites and tasks. The response JSON will be structured with nested data, for example:
json
Copy
Edit
{
  "quote_id": "...",
  "client_name": "Client A",
  "created_by": "User X",
  "labor_mode": "award",
  "margin_pct": 30,
  "monthly_price": 10000,
  "gross_profit": 4000,
  "net_profit": 3000,
  "profit_margin_pct": 30,
  "sites": [
    {
      "site_id": "...",
      "site_name": "Head Office",
      "tasks": [
        { "task_id": "...", "name": "Vacuum Carpets", "frequency_per_week": 5, "quantity": 1000, "shift": "Weekday", "monthly_hours": 86.6 },
        ...
      ]
    },
    ...
  ]
}
This allows the front-end to display or print the quote. The calculation may either be fetched from stored values or re-calculated on the fly. Since we plan to store the results, the API can just return stored numbers. Nonetheless, it will also fetch the task names, etc., via joins from the tasks table for completeness.
PUT /api/quotes/{id} – Update an existing quote. This could allow editing a quote’s details or scope after creation. For MVP, we might keep it read-only after creation (forcing users to create a new quote for changes, to preserve history). However, supporting an update is useful if a quote is in “Draft” status. This endpoint would accept a payload similar to POST and then update the quote record and associated line items (perhaps by deleting and reinserting scope items, or diffing and updating accordingly). This is a bit complex (maintaining consistency), so we might limit usage. We will include it for completeness but can restrict editing for now.
DELETE /api/quotes/{id} – Delete a quote. Marks a quote as deleted (or actually deletes). This might be used to remove test quotes or duplicates. We will implement it carefully with cascading delete of sites and items. In practice, quotes might rarely be deleted (maybe just archived), but an endpoint can exist for admin.
Configuration and Utilities APIs
GET /api/costing-configs – Get current costing configurations. Returns the list of labor cost configurations (or specifically identifies the active ones). This is used to populate the “Labor Plan” settings in the UI (e.g. showing current base wage, contractor rate, overhead %, etc.). Possibly we will mark one config as default for award and one for contractor.
PUT /api/costing-configs/{id} – Update costing config. Allows updating fields like base_hourly_rate, overhead_pct, etc. Only admin users would use this (e.g. when wages increase or new award rules apply). We could also allow creating a new config entry (POST) for versioning rather than editing in place, to preserve old configs for old quotes. In the UI, perhaps an admin can set a new default active config.
GET /api/print-quote/{id} – (Optional) Get a print-friendly format. This could return HTML or PDF of the quote for printing. Alternatively, we handle printing entirely on the client side, so this endpoint may not be necessary. If we wanted server-side PDF generation, an endpoint would trigger that.
GET /api/export/quotes – (Optional) Export quotes data. Could accept query (e.g. client or date range) and return a CSV or JSON of quote summaries. This might simply be handled on the client by calling GET /quotes and formatting, but a dedicated endpoint could streamline certain exports.
All API routes will return appropriate HTTP status codes (200 for success, 201 for created, 400 for bad input, 401/403 for unauthorized, etc.). Errors (validation issues, database errors) will be handled gracefully with messages. Note on Implementation: We will use Next.js API route handlers that leverage the Supabase client (server-side) to interact with the DB. We will wrap the multi-step quote creation in a transaction. If using Supabase JS library, one approach is to create a Postgres function to handle inserting quote, sites, and items, and call it via rpc() in one round-trip. Alternatively, use the Node Postgres client via Supabase to issue a BEGIN/COMMIT block. Ensuring atomicity is important for data consistency (so we don’t end up with half-inserted quotes if something fails midway). Security: We will enforce that the created_by field of quotes corresponds to the authenticated user. For read endpoints, if not an admin, the API will filter by created_by = user_id to ensure users only load their own quotes (if that is a requirement). If instead all internal users can see all, we may skip that filter. Regardless, all endpoints require login. Supabase Row-Level Security (RLS) policies can be configured on the quo​
ISSA.COM
nforce these access rules at the DB level as well. The combination of Next.js middleware (to check the user JWT) and DB RLS will secure the data.
Front-End Component Architecture
The front-end UI will be built in React (using Next.js pages
Front-End Component Architecture
The user interface will be built with React components and styled with Tailwind CSS, integrated into the Next.js application. The design will be intuitive and workflow-oriented, guiding the user from managing the task library to building a quote. Key parts of the interface include:
Task Database Page: A page (or tab) where the list of all cleaning tasks is displayed. This will likely be a 
ISSA.COM
​
ISSA.COM
, category, productivity rate, etc. Users with permission can add new tasks or edit existing o​
PAYCAT.COM.AU
​
PAYCAT.COM.AU
ms or modals for adding/editing tasks (fields for name, unit, productivity, etc.). It may include an import function (to load ISSA data initially, likely handled by developers or admin outside the UI). The Task list can be searchable or filterable by category for convenience.
Quote Creation Interface: This is the core UI for building a quote, which might be split into sub-sections or tabs for easier navigation. We propose a two-tab interface: Scope of Work and Labor Plan (as indicated by the provided mock-up). The user will typically:
Enter the high-level quote info (client name, etc.).
Define the Scope of Work – i.e., add sites and tasks.
Adjust the Labor Plan – i.e., set cost parameters or choose contractor vs award and profit targets.
Review the financial summary and save the quote.
【5†embed_image】The quoting interface includes a Scope of Work section where the user can add tasks for each site and immediately see the impact on costs and time. For example, the screenshot above shows input fields for a “Master Charge Rate” and “Master Cost Rate” at the top – these allow the user to set a default billing rate (charge to client per hour) and a default cost per hour, which can then be applied to all tasks. Below that is a table listing each task line with columns for Task, Category, Productivity, Area/Units, Frequency, Shift, Time per Service, Monthly Hours, Charge Rate, and Cost Rate. As tasks are added with their details, the system calculates the Time per Service and Monthly Hours automatically. A real-time Financial Summary panel (below the task table) displays metrics like Monthly Revenue, Gross Profit (before overhead & equipment), Net Profit (after all costs), and Profit Margin, as well as a breakdown of weekly, monthly, and annual figures for revenue and various costs. This dynamic feedback allows the user to adjust inputs (such as changing a task’s frequency or shifting it from a weekend to a weekday) and immediately see how the profits and costs change.
Scope of Work Component: Within the quote builder, the Scope of Work tab will contain UI elements for managing sites and their tasks. Users can add multiple sites – perhaps via an “Add Site” button which creates a new collapsible panel or section for that site. Within each site panel, there will be an “Add Task” functionality. Adding a task opens a row with a dropdown to select the task from the task library, input fields for area/quantity and frequency, and a dropdown for shift type. The UI will pull the selected task’s productivity rate to display (so the user knows the reference value). As soon as quantity and frequency are entered, the “Time per Service” and “Monthly Hours” for that line are calculated and displayed. The Charge Rate and Cost Rate columns for each line are populated based on either the global Master rates or specific overrides: if the user has not overridden them, they might all mirror the “Master” values (with cost rate auto-adjusting per shift for award mode). The user can override a line’s charge or cost if needed (e.g., click into the cell and edit it), in which case that particular line’s values will no longer follow the master default.
Labor Plan Component: In the quote interface, the Labor Plan tab allows configuration of the costing assumptions for the quote. Here the user can toggle between Award-based vs Contractor pricing modes. If Award is selected, the UI will show fields like “Base Hourly Wage”, “Casual Loading”, “Weekend Penalty”, “Holiday Penalty”, etc., pre-filled from the current Costing Config (and possibly not editable by a regular estimator if those are standardized – or they might be view-only). It will also show “Overhead %” and “Equipment $/hr” fields. If Contractor mode is selected, it will show “Contractor hourly rate” and still overhead/equipment (if those apply similarly). The user can adjust the profit target here as well – perhaps by specifying a desired Profit Margin % or by directly setting the “Charge Rate”. In the screenshot’s design, the “Master Charge Rate ($)” might correspond to setting a charge rate such that a certain margin is achieved given the cost. In practice, the UI might offer either: let the user input a margin % and auto-calc the necessary charge rate, or input a charge rate and derive margin. The Labor Plan tab basically summarizes all the financial inputs separate from the scope itself. Changes here (like increasing the base wage or overhead) will immediately reflect in the financial summary and potentially update the cost rate columns in the Scope table.
Real-time Calculations and Feedback: The React components for scope and labor plan will share state so that any change triggers a recalculation of the quote summary. We will use React state hooks or context to manage this shared state. For example, as the user edits a task’s frequency or toggles the contractor mode, the totals state is recalculated and the summary component is updated. This provides instantaneous feedback, which is crucial for the “what-if” scenario exploration. The calculation logic can run in the browser for responsiveness, using the same formulas as the back-end (we will ensure consistency by centralizing the formula in a utility module that can be used both client-side and server-side).
Quote Summary Display: As shown in the mock-up, a summary panel will be visible (probably fixed below the task list, or in a sidebar) showing key results: Monthly Revenue (the price to client), Gross Profit (before overhead and equipment costs), Net Profit (after all costs), and Profit Margin %. Additionally, a “Time-Based Financial Overview” can present weekly, monthly, annual breakdowns of revenue and cost. This summary is updated live. We will format currency values and percentages nicely (using perhaps a library or util for currency). Tailwind will be used to style these summary cards (e.g. making profits green if positive, etc., as in the screenshot where $0.00 and 0.0% are shown in green text).
Quote List Page: A page that lists saved quotes in a table or card format. Each entry might show Quote ID, client name, date, created by, and key figures (monthly revenue, profit margin). The user can click on a quote to view details (navigating to a Quote Detail page). This page helps users review past quotes. We can allow sorting or filtering by client or date for convenience. This page will fetch data via GET /api/quotes.
Quote Detail / Print View: When viewing an existing quote, we will present the information in a read-only format, suitable for printing or exporting. This could be the same interface as the creation view but with fields disabled, or a dedicated read-only layout. A “Print” button can trigger the browser’s print dialog with a print-optimized stylesheet. We will ensure a clean print layout (e.g. white background, all necessary data visible, pagination for multiple sites if needed). If needed, we could also implement a PDF download, but initially leveraging browser print is simpler. The detail view will show the breakdown by site and task, and the financial summary – essentially a formatted report of what was input and the resulting costs. This is the view that might be shared with management or kept on file.
Responsiveness and UX: The application will be primarily used on desktop by internal staff, so a desktop-first design is assumed. Tailwind will be used to create a responsive grid/table so that if needed it could be viewed on a tablet. We will use consistent ERP styling (colors, fonts) so the module feels integrated. Form inputs will have clear labels and possibly inline help (e.g. an info icon explaining what “Master Cost Rate” means, etc.). Validation feedback (e.g. if a required field is missing) will be shown to the user. We aim for short, logical forms – e.g., adding a task in the scope as one line rather than a multi-field dialog.
Under the hood, Next.js will serve these as a combination of pages and components:
We might have a Next.js page for /tasks (Task Database management), /quotes/new (New Quote builder), /quotes/[id] (Quote detail view), and /quotes (list).
Common components: TaskTable, QuoteForm, SiteSection, TaskLineItem, SummaryPanel, CostingForm (for labor plan inputs), etc., will be created to organize the UI. This modular approach means we can reuse a TaskLineItem component for each task row and it manages its own logic (e.g. calculating its time per service).
We will use local state for forms and possibly Next.js API for saving. For state management across the Scope and Labor Plan tabs, a React Context or lifting state up to the parent QuoteForm component will be done.
Calculation Engine Structure
The calculation engine is responsible for turning the input data (tasks with quantities and frequencies, labor rates, etc.) into the output metrics (hours, costs, profits). This logic will be implemented in a shared module (JavaScript/TypeScript functions) so it can be used both on the client (for instant UI updates) and on the server (for final save, or in case heavy calculations are needed server-side). Key Calculation Steps:
Per Task Time Calculation: For each scope item (task entry), compute the labor time required for one service:
If we have productivity_rate as units per hour (from the tasks DB) and a given quantity, then hours_per_service = quantity / productivity_rate.
Example: Task “Vacuum Carpets” with productivity 200 m²/hour, quantity 400 m² -> hours_per_service = 400/200 = 2.0 hours.
(If we stored minutes per unit, we’d do quantity * minutes_per_unit / 60 to get hours; it’s equivalent.)
This gives the Time per Service which is displayed in the UI.
Frequency to Monthly Factor: Determine how many times per month the task is done. If frequency was input as per week, we multiply by 4.33 (approx average weeks per month) to get per month. If frequency was per day (like daily weekdays = 5 per week), we could convert similarly (5 per week -> ~21.65 per month). Alternatively, if user inputs “monthly” we treat that as 1 per month (which is ~0.23 per week).
We will use a consistent conversion so that all tasks ultimately yield a monthly count of services. For exactness, we might base on per week and use 4.333 (which gives 52 weeks/year / 12).
Using the above example: 2.0 hours per service and frequency 5/week => services per month ≈ 21.65, so monthly_hours = 2.0 * 21.65 = 43.3 hours per month.
Aggregate Hours: Sum up the total monthly hours for all tasks in the quote. We can also sum per site if needed (e.g. to know hours per site). We will also sum by shift category:
e.g. total Weekday hours vs total Weekend hours vs Holiday hours in the quote. This is important for Award mode costing, since different hours will cost differently.
For example, if one site has 40 monthly hours of work on weekdays and another has 10 monthly hours on weekends, we know to cost 40 hours at base rate and 10 hours at weekend rate.
Labor Cost Calculation (Award mode): If labor_mode is award:
Start with the base hourly rate (from costing_config, e.g. $25/hr for a full-time Level1 or $31.25/hr for a casual including 25% loading).
Apply shift multipliers to calculate cost for each group of hours:
Weekday hours cost = hours_weekday * base_rate.
Weekend hours cost = hours_weekend * base_rate * weekend_multiplier. (If weekend_multiplier = 1.5, this effectively accounts for higher Saturday/Sunday pay. If different multipliers for Sat vs Sun were desired, we would refine by specific day, but currently one category.)
Holiday hours cost = hours_holiday * base_rate * holiday_multiplier (e.g. 2.5).
Sum these up to get total direct labor cost.
Add allowances if any are defined. For example, if we have an allowance per hour (or per shift), we could do total_allowance_cost = hourly_allowance_rate * total_hours, or if some allowances are per shift we’d need number of shifts. For simplicity, we might fold minor allowances into an effective base_rate or overhead. However, if we want to be precise: e.g., if each shift (day) a cleaner works has a $10 travel allowance and we estimate X shifts per month, that could be added. In early version, we may skip this complexity or handle it as part of overhead.
The result is the Labor Cost for the month. (This is essentially wages the company will pay its cleaners for this work.)
To illustrate: suppose base_rate = $30/hr (including casual loading), we calculated 50 hours/month on weekdays and 10 hours/month on weekends. If weekend multiplier is 1.5:
Weekday labor cost = 50 * $30 = $1500
Weekend labor cost = 10 * $30 * 1.5 = $450
Total labor = $1950. If overhead and equipment are zero and we charge say $3000, gross profit = $1050.
We also ensure to incorporate the standard loadings: e.g. the 25% casual loading can be baked into base_rate as mentioned, or if not, base_rate (for full-time) would be $25 and casual hours would be multiplied by 1.25 as well. We assume base_rate already includes whichever employment type is used (likely casual, since many cleaning staff are casual【15†L7-L15】).
Note: The Award also has rules for overtime (after 38 hours/week, etc.) and night loading (e.g. additional % for night shifts). These are beyond current scope. We assume the quote is structured to avoid overtime by distributing staff, and we treat any night work either as part of “weekday” (if after-hours cleaning on weekdays often has say 15% loading after 10pm, which we are not explicitly calculating). These could be future enhancements for more precision. For now, the main cost differentiators we handle are weekend and holiday work.
Labor Cost Calculation (Contractor mode): If labor_mode is contractor:
We have a flat contractor_hourly_rate from the config (say $45/hr that the subcontractor charges).
All hours regardless of shift are charged at this flat cost (the contractor presumably factors in any penalties into their flat rate or the contract is structured as fixed).
So, total labor cost = total_hours * contractor_rate.
(We can still categorize by shift for reporting if needed, but cost per hour remains the same across categories in this mode.)
Contractor mode typically does not involve allowances or loadings, since it’s an agreed flat fee per hour or per month. We assume per hour for simplicity.
Overhead and Equipment Costs: After labor cost is determined, we calculate overhead and equipment:
Overhead cost = overhead_pct * labor_cost (if overhead_pct is provided, e.g. 10%). This treats overhead as proportional to labor. Alternatively, some might compute overhead on revenue, but we will use labor as the base to ensure we cover internal cost overhead.
Equipment cost = equipment_cost_per_hour * total_hours. This assumes a linear relationship between hours of cleaning and usage of equipment/supplies. For example, if total_hours = 60 and equipment_cost_per_hour = $1.50, then equipment_cost = $90. (If we had different equipment for different tasks, we could refine by task, but a blended rate is fine for now.)
These costs are summed with labor cost to get Total Cost of delivering the service.
Pricing (Revenue) and Profit: The module can determine a selling price (what we charge the client) based on either a desired profit margin or a specified charge rate:
If user enters a target profit margin %, the system will compute the required monthly price. For example, if total cost is $2000 and target margin is 30%, that means net profit should be 30% of price. To achieve that, price = cost / (1 - 0.30) = ~$2857 in order to have $857 profit which is 30%. We will do this calculation when margin is input.
If user directly inputs a Master Charge Rate ($/hr) (as in the UI), we can compute revenue = total_hours * charge_rate. For instance, if total_hours = 60 and charge_rate = $60/hr, the monthly revenue = $3600. Then we can derive what margin that corresponds to given the cost.
The UI likely ties these together: adjusting margin slider updates the charge rate field, and vice versa, so the user can use whichever they prefer. The final chosen values will be used in the saved quote.
Once monthly revenue is determined, we compute Gross Profit = Revenue - Labor Cost (before adding overhead & equipment) and Net Profit = Revenue - (Labor + Overhead + Equipment). In other words, gross profit is profit before overhead/equipment, and net profit is after all costs. In our above example, if revenue $3000, labor $1950, overhead $0, equipment $0, gross profit = $1050, net profit = $1050. If we had overhead $100 and equipment $50, then gross profit still $1050, net profit = $1050 - $150 = $900.
Profit Margin % = (Net Profit / Revenue) * 100. E.g. $900/$3000 = 30%. This is shown in the summary.
Weekly/Annual Projections: These are straightforward conversions:
Weekly revenue = monthly revenue / 4.333, weekly labor cost = monthly labor / 4.333, etc.
Annual revenue = monthly revenue * 12, etc.
We’ll display those as secondary info. (Alternatively, compute from total hours per year, but since frequencies might not be perfectly monthly, using the conversion is fine.)
The calculation engine will be carefully tested with known scenarios to ensure accuracy. For example, we can cross-verify that if a single task’s data is put in, the calculations align with manual computations or known benchmarks. We will also test edge cases like zero frequencies, or all tasks on public holidays, etc., to make sure formulae hold up. Implementation: We will create a module, say quoteCalculator.js, that exports functions such as calculateQuote(quoteInput, costingConfig) -> quoteResult. This function can be used in the front-end to update state and in the backend in the POST /api/quotes to double-check and populate the stored values. Internally, it will likely break the process into sub-calculations:
calculateTaskHours(taskItem, taskDefinition) -> { hours_per_service, monthly_hours }
calculateLaborCost(hoursBreakdown, rates) -> laborCost
etc., for clarity.
By having this centralized, we avoid mismatches between what the user sees and what gets saved. On save, we will re-run the calculation with the same inputs to guard against any client-side glitch, and then store the results. We will document the formulas (even possibly show them in a help section for transparency, since some users may want to understand how the numbers are derived). In fact, citing an industry formula: “Cleaning time can be calculated as the amount of square footage to be cleaned divided by the production rate per hour, multiplied by 60 to get minutes”【13†L516-L520】 – our engine essentially automates this for each task and sums them up.
Integration with Supabase (Data & Auth)
Integrating with Supabase will primarily involve using it as our database and using its authentication mechanism to identify users. Key integration points and plans include:
Database (Postgres): All the schema described will be created in Supabase. We will use migration scripts or the Supabase UI to define the tables, relations, and constraints. Supabase being a PostgreSQL database means we can rely on SQL constraints (foreign keys between quotes, sites, tasks, etc., to maintain data integrity).
Row Level Security (RLS): Given Supabase’s security model, we will enable RLS on sensitive tables like quotes and related tables. Initially, if we decide that only the creator of a quote can view/edit it, we will write policies such that:
quotes: allow select/update/delete to users where quotes.created_by = auth.uid().
allow insert to any authenticated (with created_by set to their uid via a function or check).
quote_sites and quote_scope_items: likely will be manipulated only through our API, but we can add policies that join through the quote -> ensure the quote’s created_by matches the auth user.
If all internal users are allowed to see each other’s quotes, we might relax these rules or not enable RLS (and rely on front-end to hide unauthorized actions). But best practice is to enforce minimal rights at DB level too.
Supabase Auth: We will utilize Supabase’s built-in email/password (or other) authentication. The Next.js front-end will use the Supabase JS client to allow login. Once logged in, a user session and JWT are available, which will be passed to API calls. We can use Supabase’s middleware or manually verify the JWT in Next.js API routes to get the user’s identity (Supabase provides helpers to get the user from the auth header). This way, the API knows which user is making the request and can apply the logic accordingly (e.g. attach created_by on new quotes).
Supabase Client usage: For data fetches that are simple (like GET tasks, GET quotes list), we have two choices:
Use Next.js API routes as an intermediary (the front-end calls our API which then calls Supabase).
Or call Supabase directly from the front-end (using the JS client library).
We will adopt primarily the Next.js API approach for operations that require business logic (like creating quotes with multiple inserts and calculation). For simpler fetches (like pulling the task list or maybe pulling one quote for display), using the Supabase client directly in a React component is possible and can reduce latency (Supabase can return data directly to client). However, for consistency and to centralize access control, we may still route everything through our API. This also allows easily switching to server-side rendering if needed (Next.js getServerSideProps could fetch data securely).
Supabase Storage: Not heavily used in this module, since we are not storing files or images from users. One possible use could be storing an uploaded spreadsheet of tasks, but that’s an admin action and not needed in normal operations.
Supabase Functions (RPC): If the calculation or insertion logic becomes complex to handle in multiple round-trips, we might create a stored procedure on the database to, for example, insert a quote and all its sub-records in one go. This RPC could also enforce any additional constraints. It’s an optional optimization. Given our control in Next.js, we may simply use the server-side transaction approach as described.
Real-time: Supabase offers realtime subscriptions on table changes. We likely don’t need realtime sync for this module (multiple users editing the same quote concurrently is unlikely, and not in scope). So we will not enable realtime features here. One could imagine a scenario where an admin could watch quotes being built in realtime, but that’s not a requirement.
Performance considerations: The dataset sizes are not huge (task library maybe a few hundred tasks maximum, quotes maybe thousands over years). Queries are straightforward (indexed by IDs, etc.). Supabase can handle these easily. We will ensure to index foreign keys (which Postgres does by default for PKs) so that looking up tasks or joining tables is efficient. If we allow searching quotes by client, an index on client_name might be useful for partial matches, or we could integrate with a proper search solution later if needed (not likely necessary initially).
Deployment: Since this is part of an existing ERP, the Next.js app is presumably already deployed. We just need to update environment configuration for Supabase (URL, anon/service keys) and ensure the front-end is allowed to talk to it. Supabase will act as the single source of truth for this module’s data.
Backups and Migrations: Using Supabase means our data is stored safely in the cloud with regular backups. We will maintain migration scripts for the new tables (possibly using a tool like Supabase Migrations or Prisma if used in the project). This ensures the schema can be reproduced and versioned.
In summary, Supabase provides the back-end foundation: user auth to secure the module, and Postgres to reliably store all quote data. The front-end and API will use Supabase’s libraries and features to implement the module’s functionality in a secure, consistent manner.
Future Enhancements and Wishlist Integration
Looking forward, there are several enhancements and integrations planned (or envisioned) for the quoting module to increase its intelligence and utility:
AI Assistant for Quoting: Integrating an AI (perhaps via OpenAI GPT models or similar) to assist the user during quote creation. For example, the AI could help generate a list of recommended tasks and frequencies based on a description of a site. The user might input the building type and size, and an AI could suggest a scope of work (tasks with estimated frequencies) as a starting point. This could expedite the quoting process for new scenarios. Another use: the AI could analyze a completed quote and highlight anomalies or suggest optimizations (e.g. “Task X has very high frequency, which is driving labor cost up, consider if it’s needed so often”). Such an assistant would be integrated into the UI perhaps as a sidebar chat or a “Auto-generate scope” button. Data from the tasks library and historical quotes would train the suggestions. We’d ensure the architecture can accommodate calling out to an AI API and that the data (task definitions, etc.) can be fed as context.
Auto-Optimization Features: Building on scenario analysis, we can allow the system to automatically adjust certain parameters to meet goals. One idea is a “Optimize for Margin” tool – the user sets a desired profit margin and the system iteratively adjusts the charge rate (or suggests where to reduce costs) to hit that margin. Another idea is optimizing task scheduling: for instance, if a quote currently has some tasks on weekends, the system could calculate the cost difference if those tasks were moved to weekdays (or done during normal hours) – essentially a built-in what-if analyzer that might say “If all tasks were done on weekdays, profit would increase to X (assuming it’s feasible)”. In the future, if integrated with workforce data, it could also optimize how many staff or shifts are needed to cover the hours in the most cost-effective way (this toes into workforce management, which is out-of-scope now, but later could ensure the quote is not just cost-accurate but also operationally feasible). The calculation engine is being designed in a modular way, so adding optimization routines or goal-seek functions is feasible.
Historical Data Analysis: Over time, the company will accumulate a lot of quote data. Analyzing this can yield insights. We plan to add dashboards or reports for:
Win/Loss tracking: (If we integrate quote outcomes) – e.g. flag which quotes turned into actual contracts and compare estimated vs actual costs later on.
Pricing consistency: Ensuring similar clients or sites are quoted with similar margins – a report could list profit margins of all quotes by type.
Productivity calibration: By comparing quotes to actual labor usage (if later integrated with timesheets), the system could adjust productivity rates. For example, if every quote using a certain task ended up with overtime, maybe the productivity was overestimated.
For now, a simpler historical analysis might be an export of all quotes to CSV for analysis in Excel. In-app, we might show trends like average profit margin on all quotes this quarter, or distribution of labor vs overhead costs.
We will keep all the detailed data (down to each task line) which means in the future we can do granular analysis, such as “What tasks contribute most to cost across all quotes” or “which client segments demand more weekend work (and thus incur higher costs)”.
Integration with Other ERP Modules: While this quoting tool is standalone now, in the future it could connect to:
CRM/Contracts: If a quote is accepted by the client, the data could flow into a contract management system or a scheduling system. For example, generate a contract document or at least mark the quote as accepted and lock it. This would involve linking the quote to a client record (if not already) and possibly storing a status.
Billing: If later the ERP wants to use these quotes for billing, an integration could create a recurring invoice template from the quote (monthly charge).
Workforce Management: The quote could inform the operations team about needed staffing. For instance, if a quote has 160 hours/month of work, that’s roughly 40 hours/week – one full-time cleaner required. The module could eventually provide a breakdown like “Requires 1.0 FTE on weekdays and 0.2 FTE on weekends” as guidance. This overlaps with the concept of a “Labor Plan” possibly showing how many staff or shifts are needed. In the current design, we stop at hours and costs, but as a wishlist item, automatically translating hours into headcount (considering an employee’s workable hours) is valuable.
We have kept the schema and structure extensible for these – e.g., adding a field in quotes for status or linking to a contract ID in future won’t require major overhaul.
Refining Cost Calculations: Future award changes (like if the Award gets updated rates or new categories) will be handled by updating the costing configs. We might also incorporate multiple labor grades (e.g. Level 1 cleaner vs Level 3 supervisor) if needed for different tasks (some specialized tasks might use a higher-paid staff). This could mean each task in the library could have an associated “grade” or an override cost multiplier. The current design with override rates per task line can already accommodate special cases. A more structured approach could be to allow selecting the staff level on a task. This is not in MVP, but possible later.
UI Enhancements: Over time, we expect to improve the user experience with features like:
Templates or cloning: the ability to copy a previous quote or use a template for common contract types (e.g. an office of X size template) and then adjust specifics. This saves time on repetitive work.
Validation rules: e.g. warn if profit margin is below a threshold or if a frequency seems unusually high.
Multi-currency or multi-region support if the business expands (not immediately relevant since this is very tailored to Australian context and AUD).
All these wishlist items have been considered in the architecture so far. We have structured data in a normalized way that is easy to extend, and used a modular approach (both in code and UI) that will accommodate additional logic. The separation of concerns (task data vs quote data vs cost config) means each can evolve: for instance, hooking in an AI only needs read access to task library and maybe past quotes; optimizing schedules could use the structured breakdown of hours by shift. In conclusion, the Commercial Cleaning Quoting Module will provide a robust foundation for generating cleaning service quotes efficiently and accurately. It leverages standardized data (ISSA cleaning times【13†L480-L488】) and enforces consistency through an integrated calculation engine, while also giving users the flexibility to adjust scenarios. With a solid technical design in place, the module can be built and then iteratively enhanced with advanced features like AI guidance and deeper analytics, ensuring it remains a valuable tool for the company’s operations and sales teams. All outputs will be internally used to drive business decisions, and the module will serve as a single source of truth for quoting parameters and results, improving both the speed and accuracy of the company's commercial cleaning proposals. 